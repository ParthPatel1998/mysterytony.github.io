<!DOCTYPE html><html><head><meta charset="utf-8"><style>@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

* {
    box-sizing: border-box;
}

body {
    width: 980px;
    margin-right: auto;
    margin-left: auto;
}

body .markdown-body {
    padding: 45px;
    border: 1px solid #ddd;
    border-radius: 3px;
    word-wrap: break-word;
}

pre {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body {
  -webkit-text-size-adjust: 100%;
  text-size-adjust: 100%;
  color: #333;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body strong {
  font-weight: bold;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body input {
  font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}

.markdown-body a {
  color: #4078c0;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before {
  display: table;
  content: "";
}

.markdown-body hr:after {
  display: table;
  clear: both;
  content: "";
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
  font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body .select::-ms-expand {
  opacity: 0;
}

.markdown-body .octicon {
  font: normal normal normal 16px/1 octicons-anchor;
  display: inline-block;
  text-decoration: none;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.markdown-body .octicon-link:before {
  content: '\f05c';
}

.markdown-body:before {
  display: table;
  content: "";
}

.markdown-body:after {
  display: table;
  clear: both;
  content: "";
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body .anchor {
  display: inline-block;
  padding-right: 2px;
  margin-left: -18px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #000;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h1 .anchor {
  line-height: 1;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 .anchor {
  line-height: 1;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h3 .anchor {
  line-height: 1.2;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h4 .anchor {
  line-height: 1.2;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h5 .anchor {
  line-height: 1.1;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body h6 .anchor {
  line-height: 1.1;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  box-sizing: content-box;
  background-color: #fff;
}

.markdown-body code {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .pl-c {
  color: #969896;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
  color: #333;
}

.markdown-body .pl-ent {
  color: #63a35c;
}

.markdown-body .pl-k {
  color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
  color: #183691;
}

.markdown-body .pl-v {
  color: #ed6a43;
}

.markdown-body .pl-id {
  color: #b52a1d;
}

.markdown-body .pl-ii {
  background-color: #b52a1d;
  color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
  color: #63a35c;
  font-weight: bold;
}

.markdown-body .pl-ml {
  color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  color: #1d3e81;
  font-weight: bold;
}

.markdown-body .pl-mq {
  color: #008080;
}

.markdown-body .pl-mi {
  color: #333;
  font-style: italic;
}

.markdown-body .pl-mb {
  color: #333;
  font-weight: bold;
}

.markdown-body .pl-md {
  background-color: #ffecec;
  color: #bd2c00;
}

.markdown-body .pl-mi1 {
  background-color: #eaffea;
  color: #55a532;
}

.markdown-body .pl-mdr {
  color: #795da3;
  font-weight: bold;
}

.markdown-body .pl-mo {
  color: #1d3e81;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .plan-price-unit {
  color: #767676;
  font-weight: normal;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 0.35em 0.25em -1.6em;
  vertical-align: middle;
}

.markdown-body .plan-choice {
  padding: 15px;
  padding-left: 40px;
  display: block;
  border: 1px solid #e0e0e0;
  position: relative;
  font-weight: normal;
  background-color: #fafafa;
}

.markdown-body .plan-choice.open {
  background-color: #fff;
}

.markdown-body .plan-choice.open .plan-choice-seat-breakdown {
  display: block;
}

.markdown-body .plan-choice-free {
  border-radius: 3px 3px 0 0;
}

.markdown-body .plan-choice-paid {
  border-radius: 0 0 3px 3px;
  border-top: 0;
  margin-bottom: 20px;
}

.markdown-body .plan-choice-radio {
  position: absolute;
  left: 15px;
  top: 18px;
}

.markdown-body .plan-choice-exp {
  color: #999;
  font-size: 12px;
  margin-top: 5px;
}

.markdown-body .plan-choice-seat-breakdown {
  margin-top: 10px;
  display: none;
}

.markdown-body :checked+.radio-label {
  z-index: 1;
  position: relative;
  border-color: #4078c0;
}
</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>chapter9</title></head><body><article class="markdown-body"><p><a href="http://tonyli.tk/">&lt;- Go Back</a></p>

<h1>
<a id="user-content-chapter-9-multivariate-distribution" class="anchor" href="#chapter-9-multivariate-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chapter 9: Multivariate Distribution</h1>

<h2>
<a id="user-content-91-basic-terminology-and-techniques" class="anchor" href="#91-basic-terminology-and-techniques" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.1 Basic Terminology and Techniques</h2>

<h4>
<a id="user-content-joint-probability-functions" class="anchor" href="#joint-probability-functions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Joint Probability Functions:</h4>

<p>First, suppose there are two discrete random variables $X$ and $Y$, and define the function
$$\begin{align*} f(x,y) &amp;= P(X=x \quad and \quad Y=y) \\ &amp;= P(X=x, Y=y)\end{align*}$$</p>

<p>We call $f(x,y)$ the joint probability function of $(X,Y)$. The properties of a joint probability function are similar for those for a single variable; for two random variables we have $f(x,y)\geq 0$ for all $(x,y)$ and
$$\sum_{all(x,y)}f(x,y)=1$$</p>

<p>In general,
$$f(x_1,...,x_n)=P(X_1=x_1,...,X_n=x_n)$$
if there are $n$ random variables $X_1,...,X_n$</p>

<h4>
<a id="user-content-marginal-distributions" class="anchor" href="#marginal-distributions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Marginal Distributions</h4>

<p>If we're only interested in $X$, and don't care what value $Y$ takes, we can see that
$$\begin{align*}P(X=0) &amp;= P(X=0,Y=1)+P(X=0,Y=2) \\ &amp;= f(0,1) + f(0,2) \\ &amp;= 0.3\end{align*}$$</p>

<p>In general, to find $f_1(x)$ we add over all values of $y$ where $X=x$, and to find $f_2(y)$ we add over all values of $x$ with $Y=y$. Then
$$f_1(x)=\sum_{all y}f(x,y)$$
$$f_2(y)=\sum_{all x}f(x,y)$$</p>

<h4>
<a id="user-content-independent-random-variables" class="anchor" href="#independent-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Independent Random Variables</h4>

<p>For events $A$ and $B$, we have defined $A$ and $B$ to be independent if and only if $P(AB)=P(A)P(B)$. This definition can be extended to random variables $(X,Y)$. Two random variable are independent if their joint probability function is the product of the marginal probability functions.</p>

<h4>
<a id="user-content-definition" class="anchor" href="#definition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>$X$ and $Y$ are <strong>independent</strong> random variables if $f(x,y)=f_1(x)f_2(y)$ for all values $(x,y)$.</p>

<blockquote>
<p>Be careful applying this definition. You can only conclude that $X$ and $Y$ are independent after checking all $(x,y)$ combinations. Each a single case where $f_1(x)f_2(y)\neq f(x,y)$ makes $X$ and $Y$ dependent random variables.</p>
</blockquote>

<h4>
<a id="user-content-conditional-probability-functions" class="anchor" href="#conditional-probability-functions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conditional Probability Functions</h4>

<p>Again we can extend a definition from events to random variables. For events $A$ and $B$, re call that
$$P(A|B)=\frac{P(AB)}{P(B)}$$ provided $P(B)&gt;0$</p>

<p>Since
$$P(X=x|Y=y)=\frac{P(X=x, Y=y)}{P(Y=y)}$$ provided $P(Y=y)&gt;0$,
we make the following definition.</p>

<h4>
<a id="user-content-definition-1" class="anchor" href="#definition-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>The conditional probability function of $X$ given $Y=y$ is
$$f_1(x|y)=\frac{f(x,y)}{f_2{y}}$$
Similarly, the conditional probability function of $Y$ given $X=x$ is
$$f_2(y|x)=\frac{f(x,y)}{f_1(x)}$$</p>

<h4>
<a id="user-content-functions-of-random-variables" class="anchor" href="#functions-of-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Functions of Random Variables</h4>

<p>The most general method for finding the probability function for some function of random variables $X$ and $Y$ involves looking at every combination $(x,y)$ to see what values the function takes.</p>

<h4>
<a id="user-content-theorem" class="anchor" href="#theorem" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem</h4>

<p>If $X~Poi(\mu_1)$ and  $Y~Poi(\mu_2)$ independently then $T=X+Y~Poi(\mu_1+\mu_2)$</p>

<h4>
<a id="user-content-theorem-1" class="anchor" href="#theorem-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem</h4>

<p>If $X~Bin(n,p)$ and $Y~Bin(m,p)$ independently then $T=X+Y~Bin(n+m,p)$</p>

<h2>
<a id="user-content-92-multinomial-distribution" class="anchor" href="#92-multinomial-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.2 Multinomial Distribution</h2>

<p>It is a generalization of the Binomial model to the case where each trial has $k$ possible outcomes.</p>

<h4>
<a id="user-content-physical-setup" class="anchor" href="#physical-setup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Physical Setup</h4>

<p>Suppose an experiment is repeated independently $n$ times with $k$ distinct types of outcome each time. Let the probabilities of these $k$ types be $p_1,...,p_k$ each time. Let $X_1$ be the number of times the first type occurs, and $X_k$ the number of times the k-th type occurs. Then $(X_1,...,X_k)$ has a Multinomial distribution.</p>

<h4>
<a id="user-content-note" class="anchor" href="#note" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note</h4>

<ol>
<li> $p_1+\cdots+p_k=1$</li>
<li> $X_1+\cdots+X_k=n$</li>
</ol>

<h4>
<a id="user-content-joint-probability-function" class="anchor" href="#joint-probability-function" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Joint Probability Function</h4>

<p>$$f(x_1,...,x_k)=\frac{n!}{x_1!\cdots x_k!}p_1^{x_1}\cdots p_k^{x_k}$$</p>

<p>The restriction on the $x_i$ are $x_i=0,1,...,n$ and $\sum_{i=1}^{k}x_i=n$</p>

<h2>
<a id="user-content-94-expectation-for-multivariate-distributions-covariance-and-correlation" class="anchor" href="#94-expectation-for-multivariate-distributions-covariance-and-correlation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.4 Expectation for Multivariate Distributions: Covariance and Correlation</h2>

<h4>
<a id="user-content-definition-2" class="anchor" href="#definition-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>$$E[g(X,Y)]=\sum_{all (x,y)}g(x,y)f(x,y)$$</p>

<h4>
<a id="user-content-property-of-multivariate-expectation" class="anchor" href="#property-of-multivariate-expectation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Property of Multivariate Expectation</h4>

<p>$$E[ag_1(X,Y)+bg_2(X,Y)]=aE[g_1(X,Y)]+bE[g_2(X,Y)]$$</p>

<h4>
<a id="user-content-relationship-between-variables" class="anchor" href="#relationship-between-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Relationship between variables</h4>

<p>Independence is a "yes/no" way of defining a relationship between variables. We all know that there can be different types of relationships between variables which are dependent. More generally, two random variables may be related (non-independent) in a probabilistic sense.</p>

<h4>
<a id="user-content-definition-3" class="anchor" href="#definition-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>The <strong>covariance</strong> of $X$ and $Y$, denoted $Cov(X,Y)$ or $\sigma_{XY}$, is
$$Cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)]$$</p>

<p>Note that $Cov(X,Y)=E(XY)-E(X)E(Y)$</p>

<h4>
<a id="user-content-interpretation-of-covariance" class="anchor" href="#interpretation-of-covariance" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Interpretation of Covariance</h4>

<ol>
<li>Suppose large values of X tend to occur with large values of Y and small values of X with small values of Y. Then $(X-\mu_X)$ and $(Y-\mu_Y)$ will tend to be of the same sign, whether positive or negative. Thus $(X-\mu_X)(Y-\mu_Y)$ will be positive. Hence $Cov(X,Y)&gt;0$.</li>
<li> Suppose large values of X tend to occur with small values of Y and small values of X with large values of Y. Then $(X-\mu_X)$ and $(Y-\mu_Y)$ will tend to be opposite signs. Thus $(X-\mu_X)(Y-\mu_Y)$ will be negative. Hence $Cov(X,Y)&lt;0$.</li>
</ol>

<h4>
<a id="user-content-theorem-2" class="anchor" href="#theorem-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem</h4>

<p>If $X$ and $Y$ are independent then $Cov(X,Y)=0$</p>

<h4>
<a id="user-content-theorem-3" class="anchor" href="#theorem-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem</h4>

<p>Suppose random variables $X$ and $Y$ are independent random variables. Then if $g_1(X)$ and $g_2(Y)$ are any two functions,
$$E[g_1(X)g_2(Y)]=E[g_1(X)]E[g_2(Y)]$$</p>

<h4>
<a id="user-content-caution" class="anchor" href="#caution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Caution</h4>

<p>This result is not reversible. If $Cov(X,Y)=0$ we cannot conclude that $X$ and $Y$ are independent random variables.</p>

<h4>
<a id="user-content-definition-4" class="anchor" href="#definition-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>The <strong>correlation coefficient</strong> of $X$ and $Y$ is
$$\rho=\frac{Cov(X,Y)}{\sigma_X \sigma_Y}$$</p>

<p>The correlation coefficient measures the strength of the linear relationship between $X$ and $Y$ and is simply a rescaled version of the covariance, scaled to lie in the interval [-1,1].</p>

<h4>
<a id="user-content-properties-of-rho" class="anchor" href="#properties-of-rho" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Properties of $\rho$</h4>

<ol>
<li> Since $\sigma_X$ and $\sigma_Y$, the standard deviations of $X$ and $Y$, are both positive, $\rho$ will have the same sign as $Cov(X,Y)$. Hence the interpretation of the sign of $rho$ is the same as for $Cov(X,Y)$, and $\rho=0$ if $X$ and $Y$ are independent. When $\rho=0$ we way that $X$ and $Y$ are uncorrelated.</li>
<li> $-1\leq \rho \leq 1$ and as $\rho \rightarrow \pm 1$ the relation between $X$ and $Y$ becomes one to one and linear.</li>
</ol>

<h2>
<a id="user-content-95-mean-and-variance-of-a-linear-combination-of-random-variables" class="anchor" href="#95-mean-and-variance-of-a-linear-combination-of-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.5 Mean and Variance of a Linear Combination of Random Variables</h2>

<h4>
<a id="user-content-results-for-means" class="anchor" href="#results-for-means" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results for means:</h4>

<ol>
<li> $E(aX+bY)=aE(X)+bE(Y)=a\mu_X+b\mu_Y$, when $a$ and $b$ are constants. (This follows from the definition of expected value.) In particular, $E(X+Y)=\mu_X+\mu_Y$ and $E(X-Y)=\mu_X-\mu_Y$.</li>
<li> Let $a_i$ be constants (real numbers) and $E(X_i)=\mu_i$, $i=1,2,...,n$. Then $E(\sum_{i=1}^{n}a_iX_i)=\sum_{i=1}^{n}a_i\mu_i$. In particular, $E(\sum_{i=1}^{n}X_i)=\sum_{i=1}^{n}E(X_i)$.</li>
<li> Let $X_1, X_2,...,X_n$ be random variables which have mean $\mu$. (You can imagine these being some sample results from an experiment such as recording the number of occupants in cars traveling over a toll bridge.) The sample mean is $\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i$. Then $E(\bar{X})=\mu$.</li>
</ol>

<h4>
<a id="user-content-results-for-covariances" class="anchor" href="#results-for-covariances" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results for covariances:</h4>

<ol>
<li> $Cov(X,Y)=E[(X-\mu_X)(X-\mu_X)]=E[(X-\mu)^2]=Var(X)$</li>
<li> $Cov(aX+bY,cU+dV)=acCov(X,U)+adCov(X,V)+bcCov(Y,U)+bdCov(Y,V)$ where $a,b,c,d$ are constants.</li>
</ol>

<h4>
<a id="user-content-results-for-variance" class="anchor" href="#results-for-variance" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results for variance:</h4>

<ol>
<li> Variance of a linear combination
$$Var(aX+bY)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)$$</li>
<li> Variance of a sum of independent random variables: Let $X$ and $Y$ be independent. Since $Cov(X,Y)=0$, result 1. gives
$$Var(X+Y)=\sigma_X^2+\sigma_Y^2$$
that is, for independent variables, the variance of a sum is the sum of the variance. Also note
$$Var(X-Y)=\sigma_X^2+(-1)^2\sigma_Y^2=\sigma_X^2+\sigma_Y^2$$</li>
<li> Variance of a general linear combination of random variables: Let $a_i$ be constants and $Var(X_i)=\sigma_i^2$. Then
$$Var(\sum_{i=1}^{n}a_iX_i)=\sum_{i=1}^{n}\sigma_i^2 \sigma_i^2+2\sum_{i=1}^{n}\sum_{j=i+1}^{n}a_i a_j Cov(X_i, X_j)$$
This is a generalization of result 1, and can be proved using either of the methods used for 1.</li>
<li> Variance of a linear combination of independent random variables: Special cases of result 3. are:

<ol>
<li> If $X_1,...,X_n$ are independent then $Cov(X_1,X_j)=0$, so that
$$Var(\sum_{i=1}^{n}a_iX_i)=\sum_{i=1}^{n}\sigma_i^2\sigma_i^2$$</li>
<li> If $X_1,...,X_n$ are independent and all have the same variance $\sigma^2$, then
$$Var(\bar{X})=\frac{\sigma^2}{n}$$</li>
</ol>
</li>
</ol>

<h4>
<a id="user-content-remark" class="anchor" href="#remark" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>This result is a very important one in probability and statistics. To recap, it says that if $X_1,...,X_n$ are independent random variables with the same mean $\mu$ and the same variance $\sigma^2$, then the sample mean $\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i$ has $E(\bar{X})=\mu$ and $Var(\bar{X})=\frac{\sigma^2}{n}$.</p>

<h2>
<a id="user-content-96-linear-combinations-of-independent-normal-random-variables" class="anchor" href="#96-linear-combinations-of-independent-normal-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.6 Linear Combinations of Independent Normal Random Variables</h2>

<h4>
<a id="user-content-theorem-linear-combinations-of-independent-normal-random-variables" class="anchor" href="#theorem-linear-combinations-of-independent-normal-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem: Linear Combinations of Independent Normal Random Variables</h4>

<ol>
<li> Let $X~N(\mu,\sigma^2)$ and $Y=aX+b$, where $a$ and $b$ are constant real numbers. Then $Y~N(a\mu+b,a^2\mu^2)$</li>
<li> Let $X~N(\mu_1,\sigma_1^2)$ and $Y~N(\mu_2,\sigma_2^2)$ independently, and let $a$ and $b$ be constants. Then $aX+bY~N(a\mu_1+b\mu_2,a^2\sigma_1^2+b^2\sigma_2^2)$.</li>
<li> Let $X_1,...,X_n$ be independent $N(\mu,\sigma^2)$ random variables. Then $\sum_{i=1}^{n}X_i~N(n\mu,n\sigma^2)$ and $\bar{X}~N(\mu,\sigma^2/n)$.</li>
</ol>

<h2>
<a id="user-content-97-indicator-random-variables" class="anchor" href="#97-indicator-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9.7 Indicator Random Variables</h2>

<p>The results for linear combinations of random variables provide a way of breaking up more complicated problems, involving mean and variance, into simpler pieces using indicator variables; an indicator variable is just a binary variable (0 or 1) that indicates whether or not some event occurs.</p>

<h4>
<a id="user-content-remark-1" class="anchor" href="#remark-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>If $X_i$ is a binary random variable with $P(X_i=1)=p=1-P(X_i=0)$ then $E(X_i)=p$ and $Var(X_i)=p(1-p)$. In some problems that $X_i$'s are not independent, and then we also need covariances.</p>

<p><strong>Consult the examples in the text book: page 221 to 225. Examples are not illustrated here as there is no significant amount of notes.</strong></p>
</article></body></html>