<!DOCTYPE html><html><head><meta charset="utf-8"><style>/* {
}

body {
    padding-left: 10px;
    padding-right: 10px;
    margin-right: auto;
    margin-left: auto;
}

body .markdown-body {
    padding: 15px;
    border: 1px solid #ddd;
    border-radius: 3px;
    word-wrap: break-word;
}

pre {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body {
    -webkit-text-size-adjust: 100%;
    text-size-adjust: 100%;
    color: #333;
    font-family: "Segoe UI", Frutiger, "Frutiger Linotype", "Dejavu Sans", "Helvetica Neue", Arial, sans-serif;
    font-size: 20px;
    line-height: 1.2;
    word-wrap: break-word;
}

.markdown-body a {
    background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
    outline: 0;
}

.markdown-body strong {
    font-weight: bold;
    color: #BC0000;
}

.markdown-body h1 {
    margin: 0.67em 0;
}

.markdown-body img {
    border: 0;
    box-shadow: 5px 5px 5px #D6D6D6;
}

.markdown-body hr {
    box-sizing: content-box;
    height: 0;
}

.markdown-body pre {
    overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
    font-family: monospace, monospace;
    font-size: 1em;
}

.markdown-body input {
    color: inherit;
    font: inherit;
    margin: 0;
}

.markdown-body html input[disabled] {
    cursor: default;
}

.markdown-body input {
    line-height: normal;
}

.markdown-body input[type="checkbox"] {
    box-sizing: border-box;
    padding: 0;
}

.markdown-body table {
    border-collapse: collapse;
    border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
    padding: 0;
}

.markdown-body input {
    font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}

.markdown-body a {
    color: #4078c0;
    text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:active {
    text-decoration: underline;
}

.markdown-body hr {
    height: 0;
    margin: 15px 0;
    overflow: hidden;
    background: transparent;
    border: 0;
    border-bottom: 1px solid #ddd;
}

.markdown-body hr:before {
    display: table;
    content: "";
}

.markdown-body hr:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 15px;
    margin-bottom: 15px;
    line-height: 1.1;
    color: #011380;
}

.markdown-body h1 {
    font-size: 30px;
}

.markdown-body h2 {
    font-size: 21px;
}

.markdown-body h3 {
    font-size: 16px;
}

.markdown-body h4 {
    font-size: 14px;
}

.markdown-body h5 {
    font-size: 12px;
}

.markdown-body h6 {
    font-size: 11px;
}

.markdown-body blockquote {
    margin: 0;
}

.markdown-body ul,
.markdown-body ol {
    padding: 0;
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
    list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
    list-style-type: lower-alpha;
}

.markdown-body dd {
    margin-left: 0;
}

.markdown-body code {
    font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
    font-size: 12px;
}

.markdown-body pre {
    margin-top: 0;
    margin-bottom: 0;
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body .select::-ms-expand {
    opacity: 0;
}

.markdown-body .octicon {
    font: normal normal normal 16px/1 octicons-anchor;
    display: inline-block;
    text-decoration: none;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
}

.markdown-body .octicon-link:before {
    content: '\f05c';
}

.markdown-body:before {
    display: table;
    content: "";
}

.markdown-body:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body>*:first-child {
    margin-top: 0 !important;
}

.markdown-body>*:last-child {
    margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
    color: inherit;
    text-decoration: none;
}

.markdown-body .anchor {
    display: inline-block;
    padding-right: 2px;
    margin-left: -18px;
}

.markdown-body .anchor:focus {
    outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 1em;
    margin-bottom: 16px;
    font-weight: bold;
    line-height: 1.4;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
    color: #000;
    vertical-align: middle;
    visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
    text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
    visibility: visible;
}

.markdown-body h1 {

    padding-bottom: 0.3em;
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}

.markdown-body h1 .anchor {
    line-height: 1;
}

.markdown-body h2 {

  border-top: 4px solid #4B0000;
  background-color: #BFADAD;
    padding: 5px;
    font-size: 1.75em;
    line-height: 1.225;
}

.markdown-body h2 .anchor {
    line-height: 1;
}

.markdown-body h3 {
    font-size: 1.5em;
    line-height: 1.43;
}

.markdown-body h3 .anchor {
    line-height: 1.2;
}

.markdown-body h4 {
    font-size: 1.25em;
}

.markdown-body h4 .anchor {
    line-height: 1.2;
}

.markdown-body h5 {
    font-size: 1em;
}

.markdown-body h5 .anchor {
    line-height: 1.1;
}

.markdown-body h6 {
    font-size: 1em;
    color: #777;
}

.markdown-body h6 .anchor {
    line-height: 1.1;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
    margin-top: 0;
    margin-bottom: 16px;
}

.markdown-body hr {
    height: 4px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
    padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body li>p {
    margin-top: 16px;
}

.markdown-body dl {
    padding: 0;
}

.markdown-body dl dt {
    padding: 0;
    margin-top: 16px;
    font-size: 1em;
    font-style: italic;
    font-weight: bold;
}

.markdown-body dl dd {
    padding: 0 16px;
    margin-bottom: 16px;
}

.markdown-body blockquote {
    padding: 0 15px;
    color: #012A58;
    border-left: 4px solid #68AFFF;
    background-color: #BAD9FB
}

.markdown-body blockquote>:first-child {
    margin-top: 0;
}

.markdown-body blockquote>:last-child {
    margin-bottom: 0;
}

.markdown-body table {
    display: block;
    width: 100%;
    overflow: auto;
    word-break: normal;
    word-break: keep-all;
}

.markdown-body table th {
    font-weight: bold;
    color: #012C45;
}

.markdown-body table th,
.markdown-body table td {
    padding: 6px 13px;
    border: 1px solid #4283A9;
}

.markdown-body table tr {
    background-color: #fff;
    border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
    background-color: #D1EEFF;
}

.markdown-body img {
    max-width: 100%;
    box-sizing: content-box;
    background-color: #fff;
}

.markdown-body code {
    padding: 0;
    padding-top: 0.2em;
    padding-bottom: 0.2em;
    margin: 0;
    font-size: 85%;
    background-color: #F1F1F1;
}

.markdown-body code:before,
.markdown-body code:after {
    letter-spacing: -0.2em;
    content: "\00a0";
}

.markdown-body pre>code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
}

.markdown-body .highlight {
    margin-bottom: 16px;
}

.markdown-body .highlight pre,
.markdown-body pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #FDFFCB;
    border-left: 4px solid #8E9402;
}

.markdown-body .highlight pre {
    margin-bottom: 0;
    word-break: normal;
}

.markdown-body pre {
    word-wrap: normal;
}

.markdown-body pre code {
    display: inline;
    max-width: initial;
    padding: 0;
    margin: 0;
    overflow: initial;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
    content: normal;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font-size: 11px;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .pl-c {
    color: #009B00;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
    color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
    color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
    color: #333;
}

.markdown-body .pl-ent {
    color: #63a35c;
}

.markdown-body .pl-k {
    color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
    color: #183691;
}

.markdown-body .pl-v {
    color: #ed6a43;
}

.markdown-body .pl-id {
    color: #b52a1d;
}

.markdown-body .pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.markdown-body .pl-ml {
    color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.markdown-body .pl-mq {
    color: #008080;
}

.markdown-body .pl-mi {
    color: #333;
    font-style: italic;
}

.markdown-body .pl-mb {
    color: #333;
    font-weight: bold;
}

.markdown-body .pl-md {
    background-color: #ffecec;
    color: #bd2c00;
}

.markdown-body .pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.markdown-body .pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.markdown-body .pl-mo {
    color: #1d3e81;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .plan-price-unit {
    color: #767676;
    font-weight: normal;
}

.markdown-body .task-list-item {
    list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
    margin-top: 3px;
}

.markdown-body .task-list-item input {
    margin: 0 0.35em 0.25em -1.6em;
    vertical-align: middle;
}

.markdown-body .plan-choice {
    padding: 15px;
    padding-left: 40px;
    display: block;
    border: 1px solid #e0e0e0;
    position: relative;
    font-weight: normal;
    background-color: #fafafa;
}

.markdown-body .plan-choice.open {
    background-color: #fff;
}

.markdown-body .plan-choice.open .plan-choice-seat-breakdown {
    display: block;
}

.markdown-body .plan-choice-free {
    border-radius: 3px 3px 0 0;
}

.markdown-body .plan-choice-paid {
    border-radius: 0 0 3px 3px;
    border-top: 0;
    margin-bottom: 20px;
}

.markdown-body .plan-choice-radio {
    position: absolute;
    left: 15px;
    top: 18px;
}

.markdown-body .plan-choice-exp {
    color: #999;
    font-size: 12px;
    margin-top: 5px;
}

.markdown-body .plan-choice-seat-breakdown {
    margin-top: 10px;
    display: none;
}

.markdown-body:checked+.radio-label {
    z-index: 1;
    position: relative;
    border-color: #4078c0;
    }*/


/*.MathJax_Display {
    color: #4B0158;
    padding-top: 5px;
    padding-bottom: 5px;
    background-color: #FEFAFF
    }*/


/* Extracted and interpreted from adcstyle.css and frameset_styles.css */


/* body */

body {
    margin: 20px auto;
    width: 80%;
    background-color: #fff;
    color: #000;
    /*font: 20px "Myriad Pro", "Lucida Grande", Lucida, Verdana, sans-serif;*/
    font: 20px Georgia, serif;
    line-height: 1.3;
}

p {
    text-indent: 50px;
}

/* links */

a:link {
    color: #00f;
    text-decoration: none;
}

a:visited {
    color: #00a;
    text-decoration: none;
}

a:hover {
    color: #f60;
    text-decoration: underline;
}

a:active {
    color: #f60;
    text-decoration: underline;
}


/* html tags */


/*  Work around IE/Win code size bug - courtesy Jesper, waffle.wootest.net  */


/** html code {
    font-size: 101%;
}

* html pre {
    font-size: 101%;
    }*/


/* code */

pre,
code {
    font-size: 20px;
    font-family: monaco, courier, consolas, monospace;
}

code {
    background-color: #EFEFEF;
    padding: 3px;
}

pre {
    margin-top: 5px;
    margin-bottom: 10px;
    border: 1px solid #c7cfd5;
    background: #f1f5f9;
    margin: 20px 0;
    padding: 8px;
    text-align: left;
    border-radius: 3px;
    border-left-width: 3px;
    border-left-color: #94B0F7;
    white-space: pre-wrap;
    /* CSS3 */
    white-space: -moz-pre-wrap;
    /* Firefox */
    white-space: -pre-wrap;
    /* Opera <7 */
    white-space: -o-pre-wrap;
    /* Opera 7 */
    word-wrap: break-word;
    /* IE */
}

blockquote {
    margin-top: 5px;
    margin-bottom: 10px;
    border: 1px solid #D5D5C7;
    background: #F9F9F1;
    margin: 20px 0;
    padding: 8px;
    text-align: left;
    border-radius: 3px;
    border-left-width: 3px;
    border-left-color: #E6E770;
    white-space: pre-wrap;
    /* CSS3 */
    white-space: -moz-pre-wrap;
    /* Firefox */
    white-space: -pre-wrap;
    /* Opera <7 */
    white-space: -o-pre-wrap;
    /* Opera 7 */
    word-wrap: break-word;
    /* IE */
}

hr {
    color: #919699;
    size: 1;
    width: 100%;
    noshade: "noshade"
}


/* headers */

h1,
h2,
h3,
h4,
h5,
h6 {
    /*font-family: "Myriad Pro", "Lucida Grande", Lucida, Verdana, sans-serif;*/
    font-weight: bold;
}

h1 {
    margin-top: 1em;
    margin-bottom: 25px;
    color: #000;
    font-weight: bold;
    font-size: 35px;
    text-align: center;
}

h2 {
    margin-top: 2.5em;
    font-size: 30px;
    color: #000;
    padding-bottom: 2px;
    border-bottom: 1px solid #919699;
    border-left-style: solid;
    border-left-width: 15px;
    border-left-color: #000565;
    padding-left: 5px;
}

h3 {
    margin-top: 2em;
    margin-bottom: .5em;
    font-size: 25px;
    color: #000;
}

h4 {
    /*margin-top: 2em;*/
    /*margin-top: 5px;*/
    margin-bottom: .5em;
    font-size: 23px;
    color: #000;
}

h5 {
    margin-top: 5px;
    margin-bottom: .5em;
    padding: 0;
    font-size: 21px;
    color: #000;
}

h6 {
    margin-top: 20px;
    margin-bottom: .5em;
    padding: 0;
    font-size: 11px;
    color: #000;
}

p {
    margin-top: 0px;
    margin-bottom: 10px;
}


/* lists */

ul {
    list-style: square outside;
    margin: 0 0 0 30px;
    padding: 0 0 12px 6px;
}

li {
    margin-top: 7px;
}

ol {
    list-style-type: decimal;
    list-style-position: outside;
    margin: 0 0 0 30px;
    padding: 0 0 12px 6px;
}

ol ol {
    list-style-type: lower-alpha;
    list-style-position: outside;
    margin: 7px 0 0 30px;
    padding: 0 0 0 10px;
}

ul ul {
    margin-left: 40px;
    padding: 0 0 0 6px;
}

li>p {
    display: inline
}

li>p+p {
    display: block
}

li>a+p {
    display: block
}


/* table */

table {
    border-top: 1px solid #919699;
    border-left: 1px solid #919699;
    border-spacing: 0;
}

table th {
    padding: 4px 8px 4px 8px;
    background: #E2E2E2;
    /*font-size: 12px;*/
    border-bottom: 1px solid #919699;
    border-right: 1px solid #919699;
}

table th p {
    font-weight: bold;
    margin-bottom: 0px;
}

table td {
    padding: 8px;
    /*font-size: 12px;*/
    vertical-align: top;
    border-bottom: 1px solid #919699;
    border-right: 1px solid #919699;
}

table td p {
    margin-bottom: 0px;
}

table td p + p {
    margin-top: 5px;
}

table td p + p + p {
    margin-top: 5px;
}


/* forms */

form {
    margin: 0;
}

button {
    margin: 3px 0 10px 0;
}

input {
    vertical-align: middle;
    padding: 0;
    margin: 0 0 5px 0;
}

select {
    vertical-align: middle;
    padding: 0;
    margin: 0 0 3px 0;
}

textarea {
    margin: 0 0 10px 0;
    width: 100%;
}

img {
    max-height: 400px; /* you can use % */
    max-width: 400px;
    height: auto;
    width: auto;
    border-style: solid;
    border-color: #B4B4B4;
    border-width: 2px;
}

.markdown-body .pl-c {
    color: #009B00;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
    color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
    color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
    color: #333;
}

.markdown-body .pl-ent {
    color: #63a35c;
}

.markdown-body .pl-k {
    color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
    color: #183691;
}

.markdown-body .pl-v {
    color: #ed6a43;
}

.markdown-body .pl-id {
    color: #b52a1d;
}

.markdown-body .pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.markdown-body .pl-ml {
    color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.markdown-body .pl-mq {
    color: #008080;
}

.markdown-body .pl-mi {
    color: #333;
    font-style: italic;
}

.markdown-body .pl-mb {
    color: #333;
    font-weight: bold;
}

.markdown-body .pl-md {
    background-color: #ffecec;
    color: #bd2c00;
}

.markdown-body .pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.markdown-body .pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.markdown-body .pl-mo {
    color: #1d3e81;
}
</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>chapter2</title></head><body><article class="markdown-body"><h1>
<a id="user-content-chapter-2-statistical-models-and-maximum-likelihood-estimation" class="anchor" href="#chapter-2-statistical-models-and-maximum-likelihood-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chapter 2: Statistical Models and Maximum Likelihood Estimation</h1>

<h2>
<a id="user-content-21-choosing-a-statistical-model" class="anchor" href="#21-choosing-a-statistical-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.1 Choosing a Statistical Model</h2>

<p>A statistical model is a mathematical model that incorporates probability in some way. As described in Chapter 1, our interest here is in studying variability and uncertainty in populations and processes and drawing inferences where warranted in the presence of this uncertainty. This will be done by considering random variables that represent characteristics of randomly selected units or individuals in the population or process, and by studying the probability distributions of these random variables. It is very important to be clear about what the "target" population or process is, and exactly how the variables being considered are defined and measured.</p>

<p>A preliminary step in probability and statistics is the choice of a statistical model to suit a given application. The choice of a model is usually driven by some combination of the following three factors:</p>

<ol>
<li> Background knowledge or assumptions about the population or process which lead to certain distributions.</li>
<li> Past experience with data sets from the population or process, which has shown that certain distribution are suitable.</li>
<li> A current data set, against which models can be assessed.</li>
</ol>

<p>In probability theory, there is a large emphasis on factor 1 above, and there many "families" of probability distributions that describe certain types of situations. For example, the Binomial distribution was derived as a model for outcomes in repeated independent trials with two possible outcomes on each trial while the Poisson distribution was derived as a model for the random occurrence of events in time or space. The Gaussian or Normal distribution, on the other hand, is often used to represent the distributions of continuous measurements such as the heights or weights of individuals. This choice is based largely past experience that such models are suitable and on mathematical convenience.</p>

<p>In choosing a model we usually consider families of probability distributions. To be specific, we suppose that for a random variable $Y$ we have a family of probability functions/probability density functions, $f(y;\theta)$ indexed by the parameter $\theta$ (which may be a vector of values). In order to apply the model to a specific problem we need a value for $\theta$. The process of selecting a value for $\theta$ based on the observed data is referred as "estimating" the value of $\theta$ or "fitting" the model. The next section describes the most widely used method for estimating $\theta$.</p>

<p>Most applications requires a sequence of steps in the formulation of a model. In particular, we often start with some family of models in mind, but find after examining the data set and fitting the model that is unsuitable in certain respects. We then try other models, and perhaps look at more data, in order to work towards a satisfactory model. This is usually an iterative process, which is sometimes represented by diagrams such as</p>

<p><a href="https://camo.githubusercontent.com/0440d14935f0421d6d76f0bfdf958921868df6c9/687474703a2f2f746f6e796c692e746b2f6e6f7465732f737461743233312f636832706735352e504e47" target="_blank"><img src="https://camo.githubusercontent.com/0440d14935f0421d6d76f0bfdf958921868df6c9/687474703a2f2f746f6e796c692e746b2f6e6f7465732f737461743233312f636832706735352e504e47" alt="statistical theta" data-canonical-src="http://tonyli.tk/notes/stat231/ch2pg55.PNG" style="max-width:100%;"></a></p>

<p>Statistical devotes considerable effort to the steps of this process. However, in this course we will focus on settings in which the models are not too complicated, so that model formulation problems are minimized. There are several distributions that you should review before continuing since they will appear frequently in these notes. You should also consult the Table of Distributions in these course notes for a condensed table of properties of these distributions including their moment generating function and their moments.</p>

<h4>
<a id="user-content-properties-of-discrete-versus-continuous-random-variables" class="anchor" href="#properties-of-discrete-versus-continuous-random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Properties of Discrete versus Continuous Random Variables</h4>

<table>
<thead>
<tr>
<th>Property</th>
<th>Discrete</th>
<th>Continuous</th>
</tr>
</thead>
<tbody>
<tr>
<td>c.d.f</td>
<td>$F(x)=P(X\leq x)=\sum_{t\leq x} P(X=t)$ $F$ is a right continuous step function for all $x\in \mathbb{R}$</td>
<td>$F(x)=P(X\leq x)=\int_{-\infty}^{x}f(t)dt$ $F$ is a continuous function for all $x\in \mathbb{R}$</td>
</tr>
<tr>
<td>p.f./p.d.f.</td>
<td>$f(x)=P(X=x)$</td>
<td>$f(x)=\frac{d}{dx}F(x)\neq P(X=x)=0$</td>
</tr>
<tr>
<td>Probability of an event</td>
<td>$P(X\in A)=\sum_{x\in A}P(X=x)=\sum_{x\in A} f(x)$</td>
<td>$P(a&lt;X\leq b)=F(b)-F(a)=\int_{a}^bf(x)dx$</td>
</tr>
<tr>
<td>Total probability</td>
<td>$\sum_{all \quad x}P(X=x)=\sum_{all \quad x}f(x)=1$</td>
<td>$\int_{-\infty}^{\infty}f(x)dx=1$</td>
</tr>
<tr>
<td>Expectation</td>
<td>$E[g(X)]=\sum_{all \quad x}g(x)f(x)$</td>
<td>$E[g(X)]=\int_{-\infty}^{\infty}g(x)f(x)dx$</td>
</tr>
</tbody>
</table>

<h4>
<a id="user-content-binomial-distribution" class="anchor" href="#binomial-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Binomial Distribution</h4>

<p>The discrete random variable (r.v.) $Y$ has a Binomial distribution if its probability function is of the form </p>

<p>$$P(Y=y;\theta)=f(y;\theta)={n \choose y}\theta^y(1-\theta)^{n-y}$$</p>

<p>for $y=0,...n$</p>

<p>where $\theta$ is a parameter with $0&lt;\theta&lt;1$. For convenience we write $Y\sim$ Binomial $(n, \theta)$. Recall that $E(Y)=n\theta$ and $Var(Y)=n\theta(1-\theta)$.</p>

<h4>
<a id="user-content-poisson-distribution" class="anchor" href="#poisson-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Poisson Distribution</h4>

<p>The discrete random variable $Y$ has a Poisson distribution if its probability function is of the form</p>

<p>$$f(y;\theta)=\frac{\theta^y e^{-\theta}}{y!}$$</p>

<p>for $y=0,1,2,...$</p>

<p>where $\theta$ is a parameter with $\theta &gt; 0$. We write $Y\sim$ Poisson $(\theta)$. Recall that $E(Y)=\theta$ and $Var(Y)=\theta$.</p>

<h4>
<a id="user-content-exponential-distribution" class="anchor" href="#exponential-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exponential Distribution</h4>

<p>The continuous random variable $Y$ has an Exponential distribution if its probability density function is of the form</p>

<p>$$f(y;\theta)=\frac{1}{\theta}e^{-y/\theta}$$</p>

<p>for $y&gt;0$</p>

<p>where $\theta$ is a parameter with $\theta&gt;0$. We write $Y\sim$ Exponential $(\theta)$. Recall that $E(Y)=\theta$ and $Var(Y)=\theta^2$.</p>

<h4>
<a id="user-content-gaussian-normal-distribution" class="anchor" href="#gaussian-normal-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Gaussian (Normal) Distribution</h4>

<p>The continuous random variable $Y$ has a Gaussian or Normal distribution if its probability density function is of the form</p>

<p>$$f(y;\mu,\sigma)=\frac{1}{\sqrt{2}\pi\sigma}\exp{\left[-\frac{1}{2\sigma^2}(y-\mu)^2\right]}$$</p>

<p>for $y\in \mathbb{R}$</p>

<p>where $\mu$ and $\sigma$ are parameters, with $\mu\in\mathbb{R}$ and $\sigma&gt;0$. Recall that $E(Y)=\mu$, $Var(Y)=\sigma^2$, and standard deviation of $Y$ is $sd(Y)=\sigma$. We write either $Y\sim G(\mu,\sigma)$ or $Y\sim N(\mu, \sigma^2)$.</p>

<h4>
<a id="user-content-multinomial-distribution" class="anchor" href="#multinomial-distribution" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Multinomial Distribution</h4>

<p>The Multinomial distribution is a multivariate distribution in which the discrete random variable;s $Y_1,...,Y_k$ have the joint probability function</p>

<p>$$P(Y_1=y_1,...,Y_k=y_k;\theta)=f(y_1,...,y_k;\theta)=\frac{n!}{y_1!\cdots y_k!}\theta_1^{y_1}\cdots \theta_k^{y_k}$$</p>

<p>where $y_i=0,1,...$ for $i=1,..,k$ and $\sum_{i=1}^{k}y_i=n$. The elements of the parameter vector $\theta=(\theta_1,...,\theta_k)$ satisfy $0&lt;\theta_i&lt;1$ for $i=1,...,k$ and $\sum_{i=1}^{k}\theta_i=1$. This distribution is a generalization of the Binomial distribution. It arises when there are repeated independent trials, where each trial has $k$ possible outcomes and the probability outcomes $i$ occurs is $\theta_i$. If $Y_i,i=1,2,...,k$ is the number of times that outcome $i$ occurs in a sequence of $n$ independent trials, then $(Y_1,...Y_k)$ have the joint probability function. We write $(Y_1,...Y_k)\sim$ Multinomial $(n;\theta)$.</p>

<p>Since $\sum_{i=1}^{k}Y_i=n$ we can rewrite $f(y_1,...,y_k;\theta)$ using only $k-1$ variables, say $y_1,...,y_{k-1}$ by replacing $y_k$ with $n-y_1-...-y_{k-1}$. We see that the Multinomial distribution with $k=2$ is just the Binomial distribution, where the two possible outcomes are $S$ (Success) or $F$ (Failure).</p>

<p>We now turn to the problem of fitting a model. This requires estimating or assigning numerical values to the parameters in the model.</p>

<h2>
<a id="user-content-22-estimation-of-parameters-and-the-method-of-maximum-likelihood" class="anchor" href="#22-estimation-of-parameters-and-the-method-of-maximum-likelihood" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.2 Estimation of Parameters and the Method of Maximum Likelihood</h2>

<p>Suppose a probability distribution that serves as a model for some random process depends on an unknown parameter $\theta$ (possible a vector). In order to use the model we have to "estimate" or specify a value for $\theta$. To do this we usually rely on some data set that has been collected for the random variable in question. It is important that data set be collected carefully, and we consider this issue in Chapter 3. For example, suppose that the random variable $Y$ represents the weight of a randomly chosen female in some population, and that we consider a Gaussian model, $Y\sim G(\mu,\sigma)$. Since $E(Y)=\mu$, we might decide to randomly select, say 50 females from the population, measure their weights $y_1,...,y_{50}$, and use the average,</p>

<p>$$\hat{\mu}=\bar{y}=\frac{1}{50}\sum_{i=1}^{50}y_i$$</p>

<p>to estimate $\mu$. This seems sensible and similar ideas can be developed for other parameters; in particular, note that $\sigma$ must also be estimated, and you might think about how you could use $y_1,...,y_{50}$ to do this. Note that although we are estimating the parameter $\mu$ we did not write $\mu=\bar{y}$. We introduced a special notation $\hat{\mu}$. This serves a dual purpose, both to remind you that $\bar{y}$ is not exactly equal to the unknown value of the parameter $\mu$, but also indicate that $\hat{\mu}$ is a quantity derived from the data and depends on the sample. A different draw of the sample will result in a different value for $\hat{\mu}$.</p>

<h4>
<a id="user-content-definition-7" class="anchor" href="#definition-7" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 7</h4>

<p>An estimate of a parameter is the value of a function of the observed data $y_1,...,y_n$ and other known quantities such as the sample size $n$. We use $\hat{\theta}$ to denote an estimate of the parameter $\theta$.</p>

<p>Note that $\hat{\theta}=\hat{\theta}(y_1,...,y_n)=\hat{\theta}(y)$ depends on the sample $y=(y_1,...,y_n)$ drawn. A function of the data which does not involve any unknown quantities such as unknown parameters is call a statistic. The numerical summaries discussed in Chapter 1 are all examples of statistics. A point estimate is also a statistic.</p>

<p>Instead of ad hoc approach to estimation as in (2.2), it is desirable to have a general methods for estimating parameters. The method of <strong>maximum likelihood</strong> is a very general method, which we now describe.</p>

<p>Let the discrete random variable $Y$ represent potential data that will be used to estimate $\theta$, and let $y$ represent the actual observed data that are obtained in a specific application. Note that to apply the method of maximum likelihood, we must know how the data $y$ were collected. It is usually assumed here that the data set consists of measurements on a random sample of population units.</p>

<h4>
<a id="user-content-definition-8" class="anchor" href="#definition-8" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 8</h4>

<p>The likelihood function for $\theta$ is defined as</p>

<p>$$L(\theta)=L(\theta;y)=P(Y=y;\theta)$$</p>

<p>for $\theta \in \Omega$</p>

<p>where the parameter space $\Omega$ is the set of possible values for $\theta$.</p>

<p>Note that the likelihood function is a function of the parameter $\theta$ and the given data $y$. For convenience we usually write just $L(\theta)$. Also, the likelihood function is the probability what we observe that random observation $y$, considered as a function of the parameter $\theta$. Obviously values of the parameter that make our observation $y$ more probable would seem more credible or likely than those that make it less probable. Therefore values of $\theta$ for which $L(\theta)$ is large are more consistent with the observed data $y$. This seems like a "sensible" approach, and it turns out to have very good properties.</p>

<h4>
<a id="user-content-definition-9" class="anchor" href="#definition-9" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 9</h4>

<p>The value of $\theta$ which maximizes $L(\theta)$ for given data $y$ is called the maximum likelihood estimate (MLE) of $\theta$. It is the value of $\theta$ which maximizes the probability of observing the data $y$. The value is denoted by $\hat{\theta}$.</p>

<h4>
<a id="user-content-definition-10" class="anchor" href="#definition-10" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 10</h4>

<p>The <strong>relative likelihood function</strong> is defined as</p>

<p>$$R(\theta)=\frac{L(\theta)}{L(\hat{\theta})}$$</p>

<p>for $\theta\in\Omega$.</p>

<p>Note that $0\leq R(\theta) \leq 1$ for all $\theta \in \Omega$.</p>

<p>Sometimes it is easier to work with the $\log$ of the likelihood function.</p>

<h4>
<a id="user-content-definition-11" class="anchor" href="#definition-11" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 11</h4>

<p>The <strong>log likelihood function</strong> is defined as</p>

<p>$$l(\theta)=\log L(\theta)$$</p>

<p>for $\theta\in\Omega$.</p>

<p>Because functions are often (but not always!) maximized by setting their derivatives equal to zero, we can usually obtain $\hat{\theta}$ by solving the equation</p>

<p>$$\frac{d}{d\theta}l(\theta)=0$$</p>

<h4>
<a id="user-content-likelihood-function-for-a-random-sample" class="anchor" href="#likelihood-function-for-a-random-sample" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Likelihood function for a random sample</h4>

<p>In many applications the data set $Y=(Y_1,...,Y_n)$ are independent and identically distributed random variables each with probability function $f(y;\theta)$, $\theta\in\Omega$. We refer to $Y=(Y_1,...,Y_n)$ as a random sample from the distribution $f(y;\theta)$. In this case the observed data are $y=(y_1,...,y_n)$ and</p>

<p>$$L(\theta)=\prod_{i=1}^nf(y_i;\theta)$$</p>

<p>for $\theta\in\Omega$.</p>

<h4>
<a id="user-content-combining-likelihoods-based-on-independent-experiments" class="anchor" href="#combining-likelihoods-based-on-independent-experiments" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Combining likelihoods based on independent experiments</h4>

<p>In we have two data sets $y_1$ and $y_2$ from two independent studies for estimating $\theta$, then since the corresponding random variables $Y_1$ and $Y_2$ are independent we have</p>

<p>$$P(Y_1=y_1,Y_2=y_2;\theta)=P(Y_1=y_1;\theta)\times P(Y_2=y_2;\theta)$$</p>

<p>and we obtain the "combined" likelihood function $L(\theta)$ based on $y_1$ and $y_2$ together as 
$$L(\theta)=L_1(\theta)\times L_2(\theta)$$</p>

<p>for $\theta\in\Omega$</p>

<p>where $L_j(\theta)=P(Y_i=y_i;\theta)$, $j=1,2$. This idea, of course, can be extended to more than two independent studies.</p>

<h2>
<a id="user-content-23-likelihood-functions-for-continuous-distributions" class="anchor" href="#23-likelihood-functions-for-continuous-distributions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.3 Likelihood Functions for Continuous Distributions</h2>

<p>Recall that we define likelihoods for discrete random variables as the probability of observing the data $y$ or</p>

<p>$L(\theta)=L(\theta;y)=P(Y=y;\theta)$</p>

<p>For continuous distributions, $P(Y=y;\theta)$ is unsuitable as a definition of the likelihood since it always equals zero. In the continuous case, we define the likelihood function similarly to the discrete case but with the probability function $P(Y=y;\theta)$ replaced by the joint probability density function evaluated at the observed values. If $Y_1,...,Y_n$ are independent and identically distributed random variables each with probability density function $f(y;\theta)$ then the joint probability density function of $(Y_1,.,,,Y_n)$ is</p>

<p>$$\prod_{i=1}^{n}f(y_i;\theta)$$</p>

<p>and we use this to construct the likelihood function.</p>

<h4>
<a id="user-content-definition-12" class="anchor" href="#definition-12" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 12</h4>

<p>If $y_1,...,y_n$ are the observed values of a random sample from a distribution with probability density function $f(y;\theta)$, then the likelihood function is defined as</p>

<p>$$L(\theta)=L(\theta;y)=\prod_{i=1}^{n}f(y_i;\theta)$$</p>

<h2>
<a id="user-content-24-likelihood-functions-for-multinomial-models" class="anchor" href="#24-likelihood-functions-for-multinomial-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.4 Likelihood Functions for Multinomial Models</h2>

<p>Multinomial models are used in many statistical applications. From section 2.1, the Multinomial joint probability function is</p>

<p>$$f(y_1,...,y_k;\theta)=\frac{n!}{y_1!...y_k!}\prod_{i=1}^{k}\theta_{i}^{y_i}$$</p>

<p>for $y_i=0,1,...$ where $\sum y_i=n$.</p>

<p>The likelihood function for $\theta=(\theta_1,...,\theta_k)$ based on data $y_1,...,y_k$ is given by</p>

<p>$$L(\theta)=L(\theta_1,...,\theta_k)=\frac{n!}{y_1!...y_k!}\prod_{i=1}^k\theta_i^{y_i}$$</p>

<p>or more simply,</p>

<p>$$L(\theta)=\prod_{i=1}^k \theta_i^{y_i}$$</p>

<p>The log likelihood function is</p>

<p>$$l(\theta)=\sum_{i=1}^k\log \theta_i$$</p>

<p>If $y_i$ represents the number of times outcome $i$ occurred in $n$ trials, $i=1,2,...,k$, then it can be shown that</p>

<p>$$\hat{\theta}_i=\frac{y_i}{n}$$</p>

<p>are the maximum likelihood estimation of $\theta_1,...,\theta_k$.</p>

<h2>
<a id="user-content-25-invariance-property-of-maximum-likelihood-estimates" class="anchor" href="#25-invariance-property-of-maximum-likelihood-estimates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.5 Invariance Property of Maximum Likelihood Estimates</h2>

<p>Many statistical problems involve the estimation of attributes of a population or process. These attributes can often be represented as an unknown parameter or parameters in a statistical model. The method of maximum likelihood gives us a general method for estimating these unknown parameters. Sometimes the attribute of interest is a function of the unknown parameters. Fortunately the method of maximum likelihood allows us to estimate functions of unknown parameters with very little extra work. This property is called the invariance property of maximum likelihood estimates and can be stated as follows:</p>

<h4>
<a id="user-content-theorem-13" class="anchor" href="#theorem-13" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 13</h4>

<p>If $\hat{\theta}$ is the maximum likelihood estimate of $\theta$ then $g(\theta)$ is the maximum likelihood estimate of $g(\theta)$</p>

<h2>
<a id="user-content-26-checking-the-model" class="anchor" href="#26-checking-the-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.6 Checking the Model</h2>

<p>The models used in this course are probability distributions for random variables that represent variates in a population or process. A typical model has probability density function $f(y;\theta)$ if the variate $Y$ is continuous, or probability function $f(y;\theta)$ if $Y$ is discrete, where $\theta$ is (possibly) a vector of parameter values. If a family of models is to be used for some purpose then it is important to check that the model with random samples of $y$-values from the population or process.</p>

<h4>
<a id="user-content-graphical-checks-of-models" class="anchor" href="#graphical-checks-of-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Graphical Checks of Models</h4>

<p>We may also use graphical techniques for checking the fit of a model. These methods are particularly useful for continuous data.</p>

<h4>
<a id="user-content-empirical-cumulative-distribution-functions" class="anchor" href="#empirical-cumulative-distribution-functions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Empirical Cumulative Distribution Functions</h4>

<p>A second graphical procedure is to plot the empirical cumulative distribution function $\hat{F}(y)$ and then to superimpose on this a plot of the model-based cumulative distribution function. The objective is to compare two cumulative distribution functions, one that we hypothesized is the cumulative distribution function for the population, and the other obtained from the sample. If they differ a great deal, this would suggest that the hypothesized distribution is a poor fit.</p>

<h4>
<a id="user-content-qqplots" class="anchor" href="#qqplots" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>QQplots</h4>

<p>An alternative view, which is really just another method of graphing the empirical cumulative distribution function, tailored to the Normal distribution, is a graph called a qqplot. Suppose the data $Y_i,i=1,2,...,n$ were in fact drawn from the $G(\mu,\sigma)$ distribution so that the standardized variables, after we order them from smallest $Y_{(1)}$ to largest $Y_{(n)}$, are</p>

<p>$$Z_{(i)}=\frac{Y_{(i)}-\mu}{\sigma}$$</p>

<p>These behave like the ordered values from a sample of the same size taken from the $G(0,1)$ distribution. If $\Phi$ denotes the standard Normal cumulative distribution function then for $0&lt;u&lt;1$</p>

<p>$$P(\Phi(Z)\leq u)=P(Z\leq \Phi^{-1}(u))=\Phi(\Phi^{-1}(u))=u$$</p>

<p>so that $\Phi(Z)$ has a Uniform distribution. It is easy to check that the expected value of the $i$'th largest value in a random sample of size $n$ from a Uniform$(0,1)$ to be close to $\frac{i}{n+1}$. In other words we expect $Z_{(i)}=(Y_{(i)}-\mu)/\sigma$ to be approximately $\Phi^{-1}\left(\frac{i}{n+1}\right)$ or $Y_{(i)}$ to be roughly a linear function of $\Phi^{-1}\left(\frac{i}{n+1}\right)$. This is the basic argument underlying the qqlot. <strong>If the distribution is actually Normal, then a plot should be approximately linear</strong>.</p>

<p>Similarly if the data obtain from an Exponential distribution we expect a plot to be approximately linear where $F^{-1}(u)$ is the inverse of the Exponential$(1)$ cumulative distribution function given by $F^{-1}(u)=-\ln(1-u)$.</p>
</article></body></html>