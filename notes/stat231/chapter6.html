<!DOCTYPE html><html><head><meta charset="utf-8"><style>/* {
}

body {
    padding-left: 10px;
    padding-right: 10px;
    margin-right: auto;
    margin-left: auto;
}

body .markdown-body {
    padding: 15px;
    border: 1px solid #ddd;
    border-radius: 3px;
    word-wrap: break-word;
}

pre {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body {
    -webkit-text-size-adjust: 100%;
    text-size-adjust: 100%;
    color: #333;
    font-family: "Segoe UI", Frutiger, "Frutiger Linotype", "Dejavu Sans", "Helvetica Neue", Arial, sans-serif;
    font-size: 20px;
    line-height: 1.2;
    word-wrap: break-word;
}

.markdown-body a {
    background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
    outline: 0;
}

.markdown-body strong {
    font-weight: bold;
    color: #BC0000;
}

.markdown-body h1 {
    margin: 0.67em 0;
}

.markdown-body img {
    border: 0;
    box-shadow: 5px 5px 5px #D6D6D6;
}

.markdown-body hr {
    box-sizing: content-box;
    height: 0;
}

.markdown-body pre {
    overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
    font-family: monospace, monospace;
    font-size: 1em;
}

.markdown-body input {
    color: inherit;
    font: inherit;
    margin: 0;
}

.markdown-body html input[disabled] {
    cursor: default;
}

.markdown-body input {
    line-height: normal;
}

.markdown-body input[type="checkbox"] {
    box-sizing: border-box;
    padding: 0;
}

.markdown-body table {
    border-collapse: collapse;
    border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
    padding: 0;
}

.markdown-body input {
    font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}

.markdown-body a {
    color: #4078c0;
    text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:active {
    text-decoration: underline;
}

.markdown-body hr {
    height: 0;
    margin: 15px 0;
    overflow: hidden;
    background: transparent;
    border: 0;
    border-bottom: 1px solid #ddd;
}

.markdown-body hr:before {
    display: table;
    content: "";
}

.markdown-body hr:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 15px;
    margin-bottom: 15px;
    line-height: 1.1;
    color: #011380;
}

.markdown-body h1 {
    font-size: 30px;
}

.markdown-body h2 {
    font-size: 21px;
}

.markdown-body h3 {
    font-size: 16px;
}

.markdown-body h4 {
    font-size: 14px;
}

.markdown-body h5 {
    font-size: 12px;
}

.markdown-body h6 {
    font-size: 11px;
}

.markdown-body blockquote {
    margin: 0;
}

.markdown-body ul,
.markdown-body ol {
    padding: 0;
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
    list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
    list-style-type: lower-alpha;
}

.markdown-body dd {
    margin-left: 0;
}

.markdown-body code {
    font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
    font-size: 12px;
}

.markdown-body pre {
    margin-top: 0;
    margin-bottom: 0;
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body .select::-ms-expand {
    opacity: 0;
}

.markdown-body .octicon {
    font: normal normal normal 16px/1 octicons-anchor;
    display: inline-block;
    text-decoration: none;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
}

.markdown-body .octicon-link:before {
    content: '\f05c';
}

.markdown-body:before {
    display: table;
    content: "";
}

.markdown-body:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body>*:first-child {
    margin-top: 0 !important;
}

.markdown-body>*:last-child {
    margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
    color: inherit;
    text-decoration: none;
}

.markdown-body .anchor {
    display: inline-block;
    padding-right: 2px;
    margin-left: -18px;
}

.markdown-body .anchor:focus {
    outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 1em;
    margin-bottom: 16px;
    font-weight: bold;
    line-height: 1.4;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
    color: #000;
    vertical-align: middle;
    visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
    text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
    visibility: visible;
}

.markdown-body h1 {

    padding-bottom: 0.3em;
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}

.markdown-body h1 .anchor {
    line-height: 1;
}

.markdown-body h2 {

  border-top: 4px solid #4B0000;
  background-color: #BFADAD;
    padding: 5px;
    font-size: 1.75em;
    line-height: 1.225;
}

.markdown-body h2 .anchor {
    line-height: 1;
}

.markdown-body h3 {
    font-size: 1.5em;
    line-height: 1.43;
}

.markdown-body h3 .anchor {
    line-height: 1.2;
}

.markdown-body h4 {
    font-size: 1.25em;
}

.markdown-body h4 .anchor {
    line-height: 1.2;
}

.markdown-body h5 {
    font-size: 1em;
}

.markdown-body h5 .anchor {
    line-height: 1.1;
}

.markdown-body h6 {
    font-size: 1em;
    color: #777;
}

.markdown-body h6 .anchor {
    line-height: 1.1;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
    margin-top: 0;
    margin-bottom: 16px;
}

.markdown-body hr {
    height: 4px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
    padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body li>p {
    margin-top: 16px;
}

.markdown-body dl {
    padding: 0;
}

.markdown-body dl dt {
    padding: 0;
    margin-top: 16px;
    font-size: 1em;
    font-style: italic;
    font-weight: bold;
}

.markdown-body dl dd {
    padding: 0 16px;
    margin-bottom: 16px;
}

.markdown-body blockquote {
    padding: 0 15px;
    color: #012A58;
    border-left: 4px solid #68AFFF;
    background-color: #BAD9FB
}

.markdown-body blockquote>:first-child {
    margin-top: 0;
}

.markdown-body blockquote>:last-child {
    margin-bottom: 0;
}

.markdown-body table {
    display: block;
    width: 100%;
    overflow: auto;
    word-break: normal;
    word-break: keep-all;
}

.markdown-body table th {
    font-weight: bold;
    color: #012C45;
}

.markdown-body table th,
.markdown-body table td {
    padding: 6px 13px;
    border: 1px solid #4283A9;
}

.markdown-body table tr {
    background-color: #fff;
    border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
    background-color: #D1EEFF;
}

.markdown-body img {
    max-width: 100%;
    box-sizing: content-box;
    background-color: #fff;
}

.markdown-body code {
    padding: 0;
    padding-top: 0.2em;
    padding-bottom: 0.2em;
    margin: 0;
    font-size: 85%;
    background-color: #F1F1F1;
}

.markdown-body code:before,
.markdown-body code:after {
    letter-spacing: -0.2em;
    content: "\00a0";
}

.markdown-body pre>code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
}

.markdown-body .highlight {
    margin-bottom: 16px;
}

.markdown-body .highlight pre,
.markdown-body pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #FDFFCB;
    border-left: 4px solid #8E9402;
}

.markdown-body .highlight pre {
    margin-bottom: 0;
    word-break: normal;
}

.markdown-body pre {
    word-wrap: normal;
}

.markdown-body pre code {
    display: inline;
    max-width: initial;
    padding: 0;
    margin: 0;
    overflow: initial;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
    content: normal;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font-size: 11px;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .pl-c {
    color: #009B00;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
    color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
    color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
    color: #333;
}

.markdown-body .pl-ent {
    color: #63a35c;
}

.markdown-body .pl-k {
    color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
    color: #183691;
}

.markdown-body .pl-v {
    color: #ed6a43;
}

.markdown-body .pl-id {
    color: #b52a1d;
}

.markdown-body .pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.markdown-body .pl-ml {
    color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.markdown-body .pl-mq {
    color: #008080;
}

.markdown-body .pl-mi {
    color: #333;
    font-style: italic;
}

.markdown-body .pl-mb {
    color: #333;
    font-weight: bold;
}

.markdown-body .pl-md {
    background-color: #ffecec;
    color: #bd2c00;
}

.markdown-body .pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.markdown-body .pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.markdown-body .pl-mo {
    color: #1d3e81;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .plan-price-unit {
    color: #767676;
    font-weight: normal;
}

.markdown-body .task-list-item {
    list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
    margin-top: 3px;
}

.markdown-body .task-list-item input {
    margin: 0 0.35em 0.25em -1.6em;
    vertical-align: middle;
}

.markdown-body .plan-choice {
    padding: 15px;
    padding-left: 40px;
    display: block;
    border: 1px solid #e0e0e0;
    position: relative;
    font-weight: normal;
    background-color: #fafafa;
}

.markdown-body .plan-choice.open {
    background-color: #fff;
}

.markdown-body .plan-choice.open .plan-choice-seat-breakdown {
    display: block;
}

.markdown-body .plan-choice-free {
    border-radius: 3px 3px 0 0;
}

.markdown-body .plan-choice-paid {
    border-radius: 0 0 3px 3px;
    border-top: 0;
    margin-bottom: 20px;
}

.markdown-body .plan-choice-radio {
    position: absolute;
    left: 15px;
    top: 18px;
}

.markdown-body .plan-choice-exp {
    color: #999;
    font-size: 12px;
    margin-top: 5px;
}

.markdown-body .plan-choice-seat-breakdown {
    margin-top: 10px;
    display: none;
}

.markdown-body:checked+.radio-label {
    z-index: 1;
    position: relative;
    border-color: #4078c0;
    }*/


/*.MathJax_Display {
    color: #4B0158;
    padding-top: 5px;
    padding-bottom: 5px;
    background-color: #FEFAFF
    }*/


/* Extracted and interpreted from adcstyle.css and frameset_styles.css */


/* body */

body {
    margin: 20px auto;
    width: 80%;
    background-color: #fff;
    color: #000;
    /*font: 20px "Myriad Pro", "Lucida Grande", Lucida, Verdana, sans-serif;*/
    font: 20px Georgia, serif;
    line-height: 1.3;
}

p {
    text-indent: 50px;
}

/* links */

a:link {
    color: #00f;
    text-decoration: none;
}

a:visited {
    color: #00a;
    text-decoration: none;
}

a:hover {
    color: #f60;
    text-decoration: underline;
}

a:active {
    color: #f60;
    text-decoration: underline;
}


/* html tags */


/*  Work around IE/Win code size bug - courtesy Jesper, waffle.wootest.net  */


/** html code {
    font-size: 101%;
}

* html pre {
    font-size: 101%;
    }*/


/* code */

pre,
code {
    font-size: 20px;
    font-family: monaco, courier, consolas, monospace;
}

code {
    background-color: #EFEFEF;
    padding: 3px;
}

pre {
    margin-top: 5px;
    margin-bottom: 10px;
    border: 1px solid #c7cfd5;
    background: #f1f5f9;
    margin: 20px 0;
    padding: 8px;
    text-align: left;
    border-radius: 3px;
    border-left-width: 3px;
    border-left-color: #94B0F7;
    white-space: pre-wrap;
    /* CSS3 */
    white-space: -moz-pre-wrap;
    /* Firefox */
    white-space: -pre-wrap;
    /* Opera <7 */
    white-space: -o-pre-wrap;
    /* Opera 7 */
    word-wrap: break-word;
    /* IE */
}

blockquote {
    margin-top: 5px;
    margin-bottom: 10px;
    border: 1px solid #D5D5C7;
    background: #F9F9F1;
    margin: 20px 0;
    padding: 8px;
    text-align: left;
    border-radius: 3px;
    border-left-width: 3px;
    border-left-color: #E6E770;
    white-space: pre-wrap;
    /* CSS3 */
    white-space: -moz-pre-wrap;
    /* Firefox */
    white-space: -pre-wrap;
    /* Opera <7 */
    white-space: -o-pre-wrap;
    /* Opera 7 */
    word-wrap: break-word;
    /* IE */
}

hr {
    color: #919699;
    size: 1;
    width: 100%;
    noshade: "noshade"
}


/* headers */

h1,
h2,
h3,
h4,
h5,
h6 {
    /*font-family: "Myriad Pro", "Lucida Grande", Lucida, Verdana, sans-serif;*/
    font-weight: bold;
}

h1 {
    margin-top: 1em;
    margin-bottom: 25px;
    color: #000;
    font-weight: bold;
    font-size: 35px;
    text-align: center;
}

h2 {
    margin-top: 2.5em;
    font-size: 30px;
    color: #000;
    padding-bottom: 2px;
    border-bottom: 1px solid #919699;
    border-left-style: solid;
    border-left-width: 15px;
    border-left-color: #000565;
    padding-left: 5px;
}

h3 {
    margin-top: 2em;
    margin-bottom: .5em;
    font-size: 25px;
    color: #000;
}

h4 {
    /*margin-top: 2em;*/
    /*margin-top: 5px;*/
    margin-bottom: .5em;
    font-size: 23px;
    color: #000;
}

h5 {
    margin-top: 5px;
    margin-bottom: .5em;
    padding: 0;
    font-size: 21px;
    color: #000;
}

h6 {
    margin-top: 20px;
    margin-bottom: .5em;
    padding: 0;
    font-size: 11px;
    color: #000;
}

p {
    margin-top: 0px;
    margin-bottom: 10px;
}


/* lists */

ul {
    list-style: square outside;
    margin: 0 0 0 30px;
    padding: 0 0 12px 6px;
}

li {
    margin-top: 7px;
}

ol {
    list-style-type: decimal;
    list-style-position: outside;
    margin: 0 0 0 30px;
    padding: 0 0 12px 6px;
}

ol ol {
    list-style-type: lower-alpha;
    list-style-position: outside;
    margin: 7px 0 0 30px;
    padding: 0 0 0 10px;
}

ul ul {
    margin-left: 40px;
    padding: 0 0 0 6px;
}

li>p {
    display: inline
}

li>p+p {
    display: block
}

li>a+p {
    display: block
}


/* table */

table {
    border-top: 1px solid #919699;
    border-left: 1px solid #919699;
    border-spacing: 0;
}

table th {
    padding: 4px 8px 4px 8px;
    background: #E2E2E2;
    /*font-size: 12px;*/
    border-bottom: 1px solid #919699;
    border-right: 1px solid #919699;
}

table th p {
    font-weight: bold;
    margin-bottom: 0px;
}

table td {
    padding: 8px;
    /*font-size: 12px;*/
    vertical-align: top;
    border-bottom: 1px solid #919699;
    border-right: 1px solid #919699;
}

table td p {
    margin-bottom: 0px;
}

table td p + p {
    margin-top: 5px;
}

table td p + p + p {
    margin-top: 5px;
}


/* forms */

form {
    margin: 0;
}

button {
    margin: 3px 0 10px 0;
}

input {
    vertical-align: middle;
    padding: 0;
    margin: 0 0 5px 0;
}

select {
    vertical-align: middle;
    padding: 0;
    margin: 0 0 3px 0;
}

textarea {
    margin: 0 0 10px 0;
    width: 100%;
}

img {
    max-height: 400px; /* you can use % */
    max-width: 400px;
    height: auto;
    width: auto;
    border-style: solid;
    border-color: #B4B4B4;
    border-width: 2px;
}

.markdown-body .pl-c {
    color: #009B00;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
    color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
    color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
    color: #333;
}

.markdown-body .pl-ent {
    color: #63a35c;
}

.markdown-body .pl-k {
    color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
    color: #183691;
}

.markdown-body .pl-v {
    color: #ed6a43;
}

.markdown-body .pl-id {
    color: #b52a1d;
}

.markdown-body .pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.markdown-body .pl-ml {
    color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.markdown-body .pl-mq {
    color: #008080;
}

.markdown-body .pl-mi {
    color: #333;
    font-style: italic;
}

.markdown-body .pl-mb {
    color: #333;
    font-weight: bold;
}

.markdown-body .pl-md {
    background-color: #ffecec;
    color: #bd2c00;
}

.markdown-body .pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.markdown-body .pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.markdown-body .pl-mo {
    color: #1d3e81;
}
</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>chapter6</title></head><body><article class="markdown-body"><h1>
<a id="user-content-chapter-6-gaussian-response-models" class="anchor" href="#chapter-6-gaussian-response-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chapter 6: Gaussian Response Models</h1>

<h2>
<a id="user-content-61-introduction" class="anchor" href="#61-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.1 Introduction</h2>

<p>A response variate $Y$ is one whose distribution has parameters which depends on the value of other variates. For the Gaussian models we have studied so far, we assumed that we had a random sample $Y_1,...,Y_n$ from the same Gaussian distribution $G(\mu,\sigma)$. A Gaussian response model generalizes this to permit the parameters of the Gaussian distribution for $Y_i$ to depend on a vector $x_i$ of covariates (explanatory variates which are measured for the response variate $Y_i$). Gaussian models are by far the most common models used in statistics.</p>

<h4>
<a id="user-content-definition-40" class="anchor" href="#definition-40" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 40</h4>

<p>A Gaussian response model is one for which the distribution of the response variable $Y$, given the associated vector of <strong>covariates</strong> $x=(x_1,...,x_k)$ for an individual unit, is of the form</p>

<p>$$Y\sim G(\mu(x), \sigma(x))$$</p>

<p>If observations are made on $n$ randomly selected units we write the model as</p>

<p>$$Y_i \sim G(\mu(x_i), \sigma(x_i)) \quad \text{for } i = 1,2,...,n$$</p>

<p>In most examples we will assume $\sigma(x_i)=\sigma$ is constant. This assumption is not necessary but it does make the models easier to analyze. The choice of $\mu(x)$ is guided by past information and on current data from the population or process. The difference between various Gaussian response models is in the choice of the function $\mu(x)$ and the covariates. We often assume $\mu(x_i)$ is a <strong>linear function</strong> of the covariates. These models are called <strong>Gaussian linear models</strong> and can be written as</p>

<p>$$Y_i \sim G(\mu(x_i),\sigma) \text{ for } i = 1,...,n$$</p>

<p>with $\mu(x_i)=\beta_0+\sum_{j=1}^{k}\beta_j x_{ij}$</p>

<p>where $x_i = (x_{i1},...,x_{ik})$ is the vector of known covariates associated with unit $i$ and $\beta_0,...,\beta_k$ are unknown parameters. These models are also referred to as <strong>linear regression models</strong> and $\beta$ are call the regression coefficients.</p>

<h4>
<a id="user-content-remark" class="anchor" href="#remark" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Sometimes the model is written a little differently as</p>

<p>$$Y_i = \mu(x_i) + R_i \text{ where } R_i \sim G(0,\sigma)$$</p>

<p>This splits $Y_i$ into a deterministic component, $\mu(x_i)$ and a random component $R_i$</p>

<p>We now consider estimation and testing procedures for these Gaussian response models. We begin with models which have no covariates so that the observations are all from the same Gaussian distributions.</p>

<h4>
<a id="user-content-gmu-sigma-model" class="anchor" href="#gmu-sigma-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>$G(\mu, \sigma)$ Model</h4>

<p>In chapter 4 and t we discussed estimation and testing hypotheses for samples from a Gaussian distribution. Suppose that $Y\sim G(\mu, \sigma)$ models a response variate $y$ in some population or process. A random sample $Y_1,...,Y_n$ is selected, and we want to estimate the model parameters and possibly to test hypotheses about them. We can write this model in the form</p>

<p>$$Y_i = \mu + R_i \text{ where } R_i \sim G(0,\sigma)$$</p>

<p>so this is a special case of the Gaussian response model in which the mean function is constant. The estimator of the parameter $\mu$ that we used is the maximum likelihood estimator $\bar{Y}=\frac 1n \sum_{i=1}^{n}Y_i$. This estimator is also a "least squares estimator". \bar{Y} has the property that it is closer to the data than any other constant, or</p>

<p>$$\min_\mu \sum_{i=1}^{n} (Y_i-\mu)^2=\sum_{i=1}^{n}(Y_i-\bar{Y})^2$$</p>

<p>You should be able to verify this. It will turn out that the methods for estimation, constructing intervals and tests of hypothesis discussed earlier for the single Gaussian are all special case of the more general methods derived in section 6.5.</p>

<p>In the next section we begin with a simple generalization to the case in which the mean is a linear function of a single covariate.</p>

<h2>
<a id="user-content-62-simple-linear-regression" class="anchor" href="#62-simple-linear-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.2 Simple Linear Regression</h2>

<p>Many studies involve covariates $x$, as described in section 6.1. In this section we consider the case in which there is a single covariate $x$. Consider the model with independent $Y_i$ such that</p>

<p>$$Y_i \sim G(\mu(x_i), \sigma) \text{ where } \mu(x_i)=\alpha+\beta x_i$$</p>

<p>This is of the form with $(\beta_0, \beta_1)$ replaced by $(\alpha, \beta)$.</p>

<p>The likelihood function for $(\alpha, \beta, \sigma)$ is</p>

<p>$$L(\alpha, \beta, \sigma) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi} \sigma} \exp\left[ -1\frac{2\sigma^2} (y_i-\alpha-\beta x_i)^2 \right]$$</p>

<p>or more simply</p>

<p>$$L(\alpha, \beta, \sigma) = \sigma^{-n} \exp \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i-\alpha-\beta x_i)^2 \right]$$</p>

<p>The log likelihood function is</p>

<p>$$l(\alpha, \beta, \sigma) = -n\log \sigma - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i-\alpha-\beta x_i)^2$$</p>

<p>To obtain the maximum likelihood estimates we solve the three equations simultaneously. We obtain the maximum likelihood estimators</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}}$$</p>

<p>$$\tilde\alpha = \bar{Y} - \tilde\beta \bar x$$</p>

<p>$$\tilde\sigma^2 = \frac 1n \sum_{i=1}^n (Y_i-\tilde\alpha-\tilde\beta x_i)^2$$</p>

<p>We will use</p>

<p>$$S_e^2 = \frac{1}{n-2} (S_{yy}-\tilde\beta S_{xy})$$</p>

<p>as the estimator for $\sigma^2$ rather than the maximum likelihood estimator $\sigma^2$ since it can be shown that $E(S_e^2)=\sigma^2$. Note that $S_e^2$ can be more easily calculated using</p>

<p>$$S_e^2 = \frac{1}{n-2} (S_{yy}-\tilde\beta S_{xy})$$</p>

<h4>
<a id="user-content-least-squares-estimation" class="anchor" href="#least-squares-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Least squares estimation</h4>

<p>If we are given the data $(x_i,y_i)$ then one criterion which could be used to obtain a line of "best fit" to these data is to fit the line which minimizes the sum of the squares of the distances between the observed points $(x_i,y_i)$ and the fitted line $y=\alpha + \beta x$. Mathematically this means we want to find the values of $\alpha$ and $\beta$ which minimize the function</p>

<p>$$g(\alpha, \beta) = \sum_{i=1}^n (y_i - (\alpha + \beta x_i))^2$$</p>

<p>Such estimate are called <strong>least squares estimates</strong>. To find the least squares estimates we need to solve the two equations simultaneously. We note that this is equivalent to solving the maximum likelihood equations. In summary we have that the least squares estimates and the maximum likelihood estimates obtained are the same estimates. Of course the method of least squares only provides point estimates of the unknown parameter $\alpha$ and $\beta$ while assuming the model allows us to obtain both estimates and confidence intervals for the unknown parameters. We now show how to obtain confidence intervals based on the model.</p>

<h4>
<a id="user-content-distribution-of-the-estimator-tildebeta" class="anchor" href="#distribution-of-the-estimator-tildebeta" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Distribution of the estimator $\tilde\beta$</h4>

<p>Notice that we can rewrite the expression for $\tilde\beta$ as</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}} = \sum_{i=1}^{n} a_i Y_i \quad \text{where } a_i=\frac{(x_i-\bar{x})}{S_{xx}}$$</p>

<p>to make it clear that $\tilde\beta$ is a linear combination of the Normal random variables $Y_i$ and is therefore Normally distributed with easily obtained expected value and variance. In fact it is easy to show that these non-random coefficients satisfy $\sum_{i=1}^n a_i=0$ and $\sum_{i=1}^{n} a_i x_i=1$ and $\sum_{i=1}^{n} a_i^2 =1/S_{xx}$. Therefore</p>

<p>$$E(\tilde\beta) = \beta$$</p>

<p>Similarly</p>

<p>$$Var(\tilde\beta) = \frac{\sigma^2}{S_{xx}}$$</p>

<p>In summary</p>

<p>$$\tilde\beta \sim G(\beta, \frac{\sigma}{\sqrt{S_{xx}}})$$</p>

<h4>
<a id="user-content-confidence-intervals-for-beta-and-test-of-hypothesis-of-no-relationship" class="anchor" href="#confidence-intervals-for-beta-and-test-of-hypothesis-of-no-relationship" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Confidence intervals for $\beta$ and test of hypothesis of no relationship</h4>

<p>Confidence intervals for $\beta$ are important because the parameter $\beta$ represents the increase in the mean value of $Y$, resulting from an increase of one unit in the value of $x$. As well, if $\beta = 0$ then $x$ has no effect on $Y$ (within the model)</p>

<p>Since</p>

<p>$$\frac{\tilde\beta - \beta}{\sigma/\sqrt{S_{xx}}} \sim G(0,1)$$</p>

<p>holds independently of</p>

<p>$$\frac{(n-2)S_e^2}{\sigma^2} \sim \mathcal{X}^2(n-2)$$</p>

<p>then it follows that</p>

<p>$$\frac{\tilde\beta - \beta}{S_e / \sqrt{S_{xx}}} \sim t(n-2)$$</p>

<p>This pivotal quantity can be used to obtain confidence intervals for $\beta$ and to construct tests of hypotheses about $\beta$.</p>

<p>Using $t$-table find the constant $a$ such that $P(-a\leq T\leq a)=p$ where $T\sim t(n-2)$. </p>

<p>Therefore a $100p\%$ confidence interval for $\beta$ is given by</p>

<p>$$[\hat\beta \pm as_e/\sqrt{S_{xx}}]$$</p>

<p>To test the hypothesis of no relationship or $H_0:\beta = 0$ we use the test statistic</p>

<p>$$\frac{|\tilde\beta - 0|}{S_e/\sqrt{S_{xx}}}$$</p>

<p>with observed value</p>

<p>$$\frac{|\hat\beta - 0|}{s_e/\sqrt{S_{xx}}}$$</p>

<p>then p-value is given by</p>

<p>$$p-value = 2 \left( 1-P\left( T \leq \frac{|\hat{\beta}-0|}{s_e/\sqrt{S_{xx}}} \right) \right)$$</p>

<p>Note also that it can be used to obtain confidence interval or tests for $\sigma$, but these are usually of less interest than inference about $\beta$ or the other quantities below.</p>

<h4>
<a id="user-content-remark-1" class="anchor" href="#remark-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>In regression models we often "redefine" a covariate $x_i$ as $x_i'=x_i-c$ where $c$ is a constant value that makes $\sum_{i=1}^n x_i'$ close to zero. (Often we take $c=\bar{x}$).
The reason for doing this are that it reduces round-off errors in calculations, and that it makes the parameter $\alpha$ more interpretable. Note that $\beta$ does not change if we "center" $x_i$ this way, because</p>

<p>$$E(Y|x)=\alpha+\beta x = \alpha + \beta(x'+c)=(\alpha+\beta c)+ \beta x'$$</p>

<p>Thus, the intercept $\alpha$ changes if we redefine $x$, but not $\beta$. In the examples we consider here we have kept the given definition of $x_i$ for simplicity.</p>

<h4>
<a id="user-content-confidence-interval-for-the-mean-response-muxalpha--beta-x" class="anchor" href="#confidence-interval-for-the-mean-response-muxalpha--beta-x" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Confidence Interval for the mean response $\mu(x)=\alpha + \beta x$</h4>

<p>We are often interested in estimating the quantity $\mu(x) = \alpha + \beta x$ since it represents the mean response at a specified value of the covariate $x$. We can obtain a pivotal quantity for doing this. The maximum likelihood estimator of $\mu(x)$ obtained by replacing the unknown values of $\alpha$, $\beta$ by their maximum likelihood estimators,</p>

<p>$$\tilde\mu(x) = \tilde\alpha + \tilde\beta x = \bar{Y}+\tilde\beta(x-\bar{x})$$</p>

<p>since $\tilde\alpha = \bar{Y} - \tilde\beta \bar{x}$. Since</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}}$$</p>

<p>we can rewrite $\tilde\mu(x)$ as</p>

<p>$$\tilde\mu(x) = \bar{Y}+\tilde\beta(x-\bar{x})=\sum_{i=1}^{n} a_i Y_u \text{ where } a_i = \frac 1n + (x-\bar{x}) \frac{(x_i-\bar{x})}{S_{xx}}$$</p>

<p>Since $\tilde\mu(x)$ is a linear combination of Gaussian random variables it has a Gaussian distribution. We can use the above equation to determine the mean and variance of the random variable $\tilde\mu(x)$.</p>

<p>Therefore</p>

<p>$$E(\tilde\mu(x)) = \mu(x)$$</p>

<p>In other words $(\tilde\mu(x))$ is an unbiased estimator of $\mu(x)$. Also</p>

<p>$$Var(\tilde\mu(x)) = \sigma^2 \left( \frac{1}{n} + \frac{(x-\bar{X})^2}{S_{xx}} \right)$$</p>

<p>Note that the variance of $\tilde\mu$ is smallest in the middle of the data, or when $x$ is close to $\bar{x}$ and much larger when $(x-\bar{x})^2$ is large. In summary, we have shown that</p>

<p>$$\tilde\mu(x) \sim G \left( \mu(x), \sigma\sqrt{\frac{1}{n} + \frac{(x-\bar{x})^2}{S_{xx}}} \right)$$</p>

<h4>
<a id="user-content-remark-2" class="anchor" href="#remark-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Note that since $\alpha = \mu(0)$, a $95\%$ confidence interval for $\alpha$, is given with $x= 0$ which gives</p>

<p>$$\tilde\alpha \pm as_e \sqrt{\frac 1n + \frac{\bar{x}^2}{S_{xx}}}$$</p>

<p>In fact one can see that if $\bar{x}$ is large in magnitude (which means the average $x_i$ is large), then the confidence interval for $\alpha$ will be very wide. This would be disturbing if the value $x=0$ is a value of interest.</p>

<h4>
<a id="user-content-prediction-interval-for-future-response" class="anchor" href="#prediction-interval-for-future-response" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prediction Interval for Future Response</h4>

<p>Suppose we want to estimate or predict the $Y$ value for a random unit, not part of the sample, which has a specific value $x$ for its covariate. We can obtain a pivotal quantity that can be used to give a prediction interval (or interval estimate) for the future response $Y$, as follows</p>

<p>Note that $Y\sim G(\mu(x), \sigma)$ or alternatively</p>

<p>$$Y = \mu(x) +R$$</p>

<p>is independent of $Y_1,...,Y_n$. For a point estimator of $Y$ it is natural to use the maximum likelihood estimator $\tilde\mu(x)$ or $\mu(x)$. Moreover the error in the point estimator of $Y$ is given by</p>

<p>$$Y -\tilde\mu(x) = R + (\mu(x) - \tilde\mu(x))$$</p>

<p>Since $R$ is independent of $\tilde\mu(x)$ (it is not connected to the existing sample), it is the sum of independent distributed random variables and is consequently Normally distributed. Since</p>

<p>$$E(Y -  \tilde\mu(x)) = 0$$</p>

<p>and</p>

<p>$$Var(Y - \tilde\mu(x)) = \sigma^2 \left( 1+\frac 1n + \frac{(x-\bar{x})^2}{S_{xx}} \right)$$</p>

<p>we have</p>

<p>$$Y -\tilde\mu(x) \sim G \left( 0,\sigma \left( 1+\frac 1n + \frac{(x-\bar x)^2}{S_{xx}} \right)^{1/2} \right)$$</p>

<h4>
<a id="user-content-remark-3" class="anchor" href="#remark-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Care must be taken in constructing prediction intervals for values of $x$ which lie outside the interval of observed $x_i$'s since this assumes that the linear relationship holds beyond the observed data. It is dangerous since there are no data to support the assumption.</p>

<h4>
<a id="user-content-remark-4" class="anchor" href="#remark-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Note that the confidence interval for $\mu(x)$ and the prediction interval for $Y$ are winder the further away $x$ is from $\bar{x}$. Thus, as we move further away from the "middle" of the $x$'s in the data, we get winder and winder intervals for $\mu(x)$ and $Y$.</p>

<h4>
<a id="user-content-checking-the-model-assumptions-for-simple-linear-regression" class="anchor" href="#checking-the-model-assumptions-for-simple-linear-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Checking the Model Assumptions for Simple Linear Regression</h4>

<p>There are two main components in Gaussian linear response models:</p>

<ol>
<li> The assumption that $Y_i$ (given any covariates $x_i$) is Gaussian with constant standard deviation $\sigma$</li>
<li> The assumption that $E(Y_i)=\mu(x_i)$ is a linear combination of observed covariates with unknown coefficients</li>
</ol>

<p>Models should always be checked. In problems with only one $x$ covariate, a plot of the fitted line superimposed on the scatterplot of the data shows pretty clearly how well the model fits. If there are two or more covariates in the model, residual plots, which are described below, are very useful for checking the model assumptions.</p>

<p>Residuals are defined as the difference between the observed response and the fitted values. Consider the simple linear regression model for which $Y_i \sim G(\mu_i, \sigma)$ where $\mu_i = \alpha + \beta x_i$ and $R_i = Y_i -\mu_i \sim G(0, \sigma)$ The residuals are given by</p>

<p>$$\hat{r}_i = y_i - \hat\mu_i = y_i - \hat\alpha - \hat\beta x_i$$</p>

<p>The idea behind the $\hat{r}_i$ is that they can be thought of as "observed" $R_i$. This isn't exactly correct since we are using $\hat{\mu}$ instead of $\mu$ in $\hat{r}$, but if the model is correct, then the $\hat{r}$ should behave roughly like a random sample from the $G(0,\sigma)$ distribution. The $\hat{r}$ do have some features that can be used to check the model assumptions. Recall that the maximum likelihood estimate of $\alpha$ is $\hat{\alpha} = \bar{y} - \hat{\beta} \bar{x}$ which implies that $\bar{y} - \hat{\alpha} -\hat{\beta} \bar{x} = 0$ or</p>

<p>$$\frac{1}{n} \sum_{i=1}^n \hat{r}_i = 0$$</p>

<p>so that the average of the residuals is always zero.</p>

<p>Residual plots can be used to check the model assumptions. Here are three residual plots which can be used:</p>

<ol>
<li> Plot points $(x_i, \hat{r}_i)$ if the model is satisfactory the points should lie more or less horizontally within a constant band around the line $\hat{r}_i=0$</li>
<li> Plot points $(\hat{\mu}_1, \hat{r}_i)$ if the model is satisfactory the points should lie more or less horizontally within a constant band around the line $\hat{r}_i=0$</li>
<li> Plot a Normal qqplot of the residuals. If the model is satisfactory the points should lie more or less along a straight line.</li>
</ol>

<h2>
<a id="user-content-63-comparing-the-means-of-two-populations" class="anchor" href="#63-comparing-the-means-of-two-populations" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.3 Comparing the Means of Two Populations</h2>

<h4>
<a id="user-content-two-gaussian-population-with-common-variance" class="anchor" href="#two-gaussian-population-with-common-variance" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Two Gaussian Population with Common Variance</h4>

<p>Suppose $Y_{11},...,Y_{1n}$ is a random sample from the $G(\mu_1, \sigma)$ distribution and independently $Y_{21},...,Y_{2n}$ is a random sample from the $G(\mu_2, \sigma)$ distribution. Notice that we have assumed that both populations have the same variance $\sigma^2$. We use double subscripts for the $Y$'s here, the first index to indicate the population from which the sample was drawn, the second to indicate which draw from that population. We could easily conform withe the notation of (6.1) by stacking these two sets of observations in a vector of $n =n_1+ n_2$ observations:</p>

<p>$$(Y_{11},...,Y_{1n},Y_{21},...,Y_{2n})^T$$</p>

<p>and obtain the conclusions below as a special case of the linear model. Below we derive the estimates from the likelihood directly.</p>

<p>The likelihood function for $\mu_1, \mu_2,\sigma$ is</p>

<p>$$L(\mu_1,\mu_2,\sigma) = \prod_{j=1}^2\prod_{i=1}^{n_j} \frac{1}{\sqrt{2\pi}\sigma} \exp\left[ -\frac{1}{2\sigma^2}(y_{ji}-\mu_j)^2 \right]$$</p>

<p>Maximization of the likelihood function gives the maximum likelihood estimators:</p>

<p>$$\tilde \mu_1 = \frac{1}{n_1}\sum_{i=1}^{n_1}Y_{1i}=\bar{Y_1}$$</p>

<p>$$\tilde \mu_2 = \frac{1}{n_2}\sum_{i=1}^{n_2}Y_{2i}=\bar{Y_2}$$</p>

<p>$$\tilde \sigma^2 = \frac{1}{n_1+n_2}\sum_{j=1}^2\sum_{i=1}^{n_j} (Y_{ji}-\tilde \mu_j)^2$$</p>

<p>An estimator of the variance $\sigma^2$ (sometimes referred to as the pooled estimator of variance) adjusted for the degree of freedom is</p>

<p>$$S_p^2 = \frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}$$</p>

<p>$$= \frac{n_1+n_2}{n_1+n_2-2} \tilde \sigma^2$$</p>

<p>where</p>

<p>$$S_j^2 = \frac{1}{n_j-1}\sum_{i=1}^{n_j}(Y_{ji}-\bar{Y}_j)^2, j=1,2$$</p>

<p>are the sample variance obtained from the individual samples. The estimator $S_p^2$ can be written as a <strong>weighted average</strong> of the estimator $S_j^2$. In fact</p>

<p>$$S_p^2 = \frac{w_1S_1^2+w_2S_2^2}{w_1+w_2}$$</p>

<p>where the weights are $w_j = n_j-1$. Although you could substitute weights other than $n_j-1$, when you poll various estimators in order to obtain one that is better than any of those being pooled, you should do so with weights that relate to a measure of precision of the estimators. For sample variances, the number of degrees of freedom is such an indicator.</p>

<p>We will use the estimator $S_p^2$ for $\sigma^2$ rather than $\tilde \sigma^2$ since $E(S_p^2)=\sigma^2$</p>

<h4>
<a id="user-content-confidence-intervals-for-mu_1-mu_2" class="anchor" href="#confidence-intervals-for-mu_1-mu_2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Confidence Intervals for $\mu_1-\mu_2$</h4>

<p>To determine whether the two populations differ and by how much we will need to generate confidence intervals for the difference $\mu_1 - \mu_2$. First note that the maximum likelihood estimator of this difference is $\bar{Y_1}-\bar{Y_2}$ which has expected value</p>

<p>$$E(\bar{Y_1}-\bar{Y_2}) = \mu_1 - \mu_2$$</p>

<p>and variance</p>

<p>$$Var(\bar{Y_1}-\bar{Y_2})= \sigma^2(\frac{1}{n_1}+\frac{1}{n_2})$$</p>

<p>It naturally follows that an estimator of $Var(\bar{Y_1}-\bar{Y_2})$ from the pooled data is</p>

<p>$$S_p^2(\frac{1}{n_1}+\frac{1}{n_2})$$</p>

<p>and that this has $n_1+n_2-2$ degrees of freedom. This provides at least an intuitive justification for the following:</p>

<h4>
<a id="user-content-theorem-41" class="anchor" href="#theorem-41" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 41</h4>

<p>If $Y_{12},...,Y_{1n_1}$ is a random sample from the $G(\mu_1, \sigma)$ distribution and independently $Y_{22},...,Y_{2n_2}$ is a random sample from the $G(\mu_2, \sigma)$ then</p>

<p>$$\frac{(\bar{Y_1}-\bar{Y_2})-(\mu_1-\mu_2)}{S_p\sqrt{\frac{1}{n_1}+ \frac{1}{n_2}}} \sim t(n_1+n_2-2)$$</p>

<p>and</p>

<p>$$\frac{(n_1+n_2-2)S_p^2}{\sigma^2} \sim \mathcal X^2(n_1+n_2-2)$$</p>

<p>Confidence intervals or tests of hypothesis for $\mu_1-\mu_2$ and $\sigma$ can be obtained by using these pivotal quantities. In particular, a $100p\%$ confidence interval for $\mu_1-\mu_2$ is given by</p>

<p>$$\bar{y_1}-\bar{y_2} \pm as_p \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$$</p>

<p>where $P(-a \leq T \leq a) = p$ and $T \sim t(n_1+n_2-2)$.</p>

<h4>
<a id="user-content-two-gaussian-populations-with-unequal-variance" class="anchor" href="#two-gaussian-populations-with-unequal-variance" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Two Gaussian Populations with Unequal Variance</h4>

<p>The procedures above assumes that the two Gaussian distributions have the same standard deviations. Sometimes this isn't a reasonable assumption (it can be tested using a likelihood ratio test, but we will not do this here) and we must assume that $Y_{11},...,Y_{1n_1}$ is random sample from the $G(\mu_1,\sigma_1)$ distribution and independently $Y_{21},...,Y_{2n_2}$ is random sample from the $G(\mu_2,\sigma_2)$ distribution but $\sigma_1 \neq \sigma^2$. In this case there is no exact pivotal quantity which can be used to obtain a confidence interval for the difference in means $\mu_1-\mu_2$. However the random variable</p>

<p>$$\frac{\bar{Y_1}-\bar{Y_2}-(\mu_1-\mu_2)}{\sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}}$$</p>

<p>has approximately a $G(0,1)$ distribution, especially if $n_1$ and $n_2$ are both large.</p>

<p>To illustrate its use, consider the durability of paint example, where $s_1^2 = 1.2800$ and $s_2^2 = 3.5127$. These appear quite different but they are in squared units and $n_1$ and $n_2$ are small; the stand deviation $s_1 = 1.13$ and $s_2 = 1.97$ do not provide evidence against the hypothesis that $\sigma_1 = \sigma_2$ if a likelihood ratio test is carried out. Nevertheless, let us obtain a 95% confidence interval for $\mu_1-\mu_2$. This result approximate $95\%$ confidence interval for $\mu_1-\mu_2$. This resulting approximate $95\%$ confidence interval is</p>

<p>$$\bar{y_1}-\bar{y_2} \pm 1.96 \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$$</p>

<h4>
<a id="user-content-comparing-means-using-paired-data" class="anchor" href="#comparing-means-using-paired-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Comparing Means Using Paired Data</h4>

<p>Often experimental studies designed to compare means are conducted with pair of units, where the response within a pair are not independent. </p>

<h4>
<a id="user-content-pairing-and-experimental-design" class="anchor" href="#pairing-and-experimental-design" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pairing and Experimental Design</h4>

<p>In setting where the population can be arranged in pairs, the estimation of a difference in means, $\mu_1-\mu_2$, can often be made more precise by using pairing in the study. The condition for this is that the association (correlation) between $Y_1$ and $Y_2$ are positive.</p>

<h4>
<a id="user-content-final-remarks" class="anchor" href="#final-remarks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Final Remarks</h4>

<p>When you see data from a <strong>comparative study</strong> (that is, one whose objective is to compare two distributions, often through their means), you have to determine whether it involves paired data or note. Of course, a sample of $Y_{1i}$ and $Y_{2i}$ cannot be from a paired study unless there are equal numbers of each, but if there are equal numbers the study might be either "paired" or "unpaired". Note also that there is subtle difference in the study populations in paired and unpaired studies. In the former it is pairs of individual units that form the population where as in the latter there separate individual units for $Y_1$ and $Y_2$ measurements.</p>
</article></body></html>