<!DOCTYPE html><html><head><meta charset="utf-8"><style>* {
    /*box-sizing: border-box;*/
}

body {
    /*width: 980px;*/
    padding-left: 10px;
    padding-right: 10px;
    margin-right: auto;
    margin-left: auto;
}

body .markdown-body {
    padding: 15px;
    border: 1px solid #ddd;
    border-radius: 3px;
    word-wrap: break-word;
}

pre {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body {
    -webkit-text-size-adjust: 100%;
    text-size-adjust: 100%;
    color: #333;
    font-family: "Segoe UI", Frutiger, "Frutiger Linotype", "Dejavu Sans", "Helvetica Neue", Arial, sans-serif;
    font-size: 20px;
    /*font: "Segoe UI";*/
    line-height: 1.6;
    word-wrap: break-word;
}

.markdown-body a {
    background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
    outline: 0;
}

.markdown-body strong {
    font-weight: bold;
    color: #BC0000;
}

.markdown-body h1 {
    margin: 0.67em 0;
}

.markdown-body img {
    border: 0;
    box-shadow: 5px 5px 5px #D6D6D6;
}

.markdown-body hr {
    box-sizing: content-box;
    height: 0;
}

.markdown-body pre {
    overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
    font-family: monospace, monospace;
    font-size: 1em;
}

.markdown-body input {
    color: inherit;
    font: inherit;
    margin: 0;
}

.markdown-body html input[disabled] {
    cursor: default;
}

.markdown-body input {
    line-height: normal;
}

.markdown-body input[type="checkbox"] {
    box-sizing: border-box;
    padding: 0;
}

.markdown-body table {
    border-collapse: collapse;
    border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
    padding: 0;
}

.markdown-body input {
    font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}

.markdown-body a {
    color: #4078c0;
    text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:active {
    text-decoration: underline;
}

.markdown-body hr {
    height: 0;
    margin: 15px 0;
    overflow: hidden;
    background: transparent;
    border: 0;
    border-bottom: 1px solid #ddd;
}

.markdown-body hr:before {
    display: table;
    content: "";
}

.markdown-body hr:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 15px;
    margin-bottom: 15px;
    line-height: 1.1;
}

.markdown-body h1 {
    font-size: 30px;
}

.markdown-body h2 {
    font-size: 21px;
}

.markdown-body h3 {
    font-size: 16px;
}

.markdown-body h4 {
    font-size: 14px;
}

.markdown-body h5 {
    font-size: 12px;
}

.markdown-body h6 {
    font-size: 11px;
}

.markdown-body blockquote {
    margin: 0;
}

.markdown-body ul,
.markdown-body ol {
    padding: 0;
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
    list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
    list-style-type: lower-alpha;
}

.markdown-body dd {
    margin-left: 0;
}

.markdown-body code {
    font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
    font-size: 12px;
}

.markdown-body pre {
    margin-top: 0;
    margin-bottom: 0;
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body .select::-ms-expand {
    opacity: 0;
}

.markdown-body .octicon {
    font: normal normal normal 16px/1 octicons-anchor;
    display: inline-block;
    text-decoration: none;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
}

.markdown-body .octicon-link:before {
    content: '\f05c';
}

.markdown-body:before {
    display: table;
    content: "";
}

.markdown-body:after {
    display: table;
    clear: both;
    content: "";
}

.markdown-body>*:first-child {
    margin-top: 0 !important;
}

.markdown-body>*:last-child {
    margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
    color: inherit;
    text-decoration: none;
}

.markdown-body .anchor {
    display: inline-block;
    padding-right: 2px;
    margin-left: -18px;
}

.markdown-body .anchor:focus {
    outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
    margin-top: 1em;
    margin-bottom: 16px;
    font-weight: bold;
    line-height: 1.4;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
    color: #000;
    vertical-align: middle;
    visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
    text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
    visibility: visible;
}

.markdown-body h1 {

    padding-bottom: 0.3em;
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}

.markdown-body h1 .anchor {
    line-height: 1;
}

.markdown-body h2 {

  border-top: 4px solid #4B0000;
  background-color: #BFADAD;
    padding: 5px;
    font-size: 1.75em;
    line-height: 1.225;
}

.markdown-body h2 .anchor {
    line-height: 1;
}

.markdown-body h3 {
    font-size: 1.5em;
    line-height: 1.43;
}

.markdown-body h3 .anchor {
    line-height: 1.2;
}

.markdown-body h4 {
    font-size: 1.25em;
}

.markdown-body h4 .anchor {
    line-height: 1.2;
}

.markdown-body h5 {
    font-size: 1em;
}

.markdown-body h5 .anchor {
    line-height: 1.1;
}

.markdown-body h6 {
    font-size: 1em;
    color: #777;
}

.markdown-body h6 .anchor {
    line-height: 1.1;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
    margin-top: 0;
    margin-bottom: 16px;
}

.markdown-body hr {
    height: 4px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
    padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
    margin-top: 0;
    margin-bottom: 0;
}

.markdown-body li>p {
    margin-top: 16px;
}

.markdown-body dl {
    padding: 0;
}

.markdown-body dl dt {
    padding: 0;
    margin-top: 16px;
    font-size: 1em;
    font-style: italic;
    font-weight: bold;
}

.markdown-body dl dd {
    padding: 0 16px;
    margin-bottom: 16px;
}

.markdown-body blockquote {
    padding: 0 15px;
    color: #012A58;
    border-left: 4px solid #68AFFF;
    background-color: #BAD9FB
}

.markdown-body blockquote>:first-child {
    margin-top: 0;
}

.markdown-body blockquote>:last-child {
    margin-bottom: 0;
}

.markdown-body table {
    display: block;
    width: 100%;
    overflow: auto;
    word-break: normal;
    word-break: keep-all;
}

.markdown-body table th {
    font-weight: bold;
    color: #012C45;
}

.markdown-body table th,
.markdown-body table td {
    padding: 6px 13px;
    border: 1px solid #4283A9;
}

.markdown-body table tr {
    background-color: #fff;
    border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
    background-color: #D1EEFF;
}

.markdown-body img {
    max-width: 100%;
    box-sizing: content-box;
    background-color: #fff;
}

.markdown-body code {
    padding: 0;
    padding-top: 0.2em;
    padding-bottom: 0.2em;
    margin: 0;
    font-size: 85%;
    background-color: #F1F1F1;
    /*border-radius: 3px;*/
}

.markdown-body code:before,
.markdown-body code:after {
    letter-spacing: -0.2em;
    content: "\00a0";
}

.markdown-body pre>code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
}

.markdown-body .highlight {
    margin-bottom: 16px;
}

.markdown-body .highlight pre,
.markdown-body pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #FDFFCB;
    border-left: 4px solid #8E9402;
    /*border-radius: 3px;*/
}

.markdown-body .highlight pre {
    margin-bottom: 0;
    word-break: normal;
}

.markdown-body pre {
    word-wrap: normal;
}

.markdown-body pre code {
    display: inline;
    max-width: initial;
    padding: 0;
    margin: 0;
    overflow: initial;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
    content: normal;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font-size: 11px;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .pl-c {
    color: #009B00;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
    color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
    color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
    color: #333;
}

.markdown-body .pl-ent {
    color: #63a35c;
}

.markdown-body .pl-k {
    color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
    color: #183691;
}

.markdown-body .pl-v {
    color: #ed6a43;
}

.markdown-body .pl-id {
    color: #b52a1d;
}

.markdown-body .pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.markdown-body .pl-ml {
    color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.markdown-body .pl-mq {
    color: #008080;
}

.markdown-body .pl-mi {
    color: #333;
    font-style: italic;
}

.markdown-body .pl-mb {
    color: #333;
    font-weight: bold;
}

.markdown-body .pl-md {
    background-color: #ffecec;
    color: #bd2c00;
}

.markdown-body .pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.markdown-body .pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.markdown-body .pl-mo {
    color: #1d3e81;
}

.markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
    line-height: 10px;
    color: #555;
    vertical-align: middle;
    background-color: #fcfcfc;
    border: solid 1px #ccc;
    border-bottom-color: #bbb;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .plan-price-unit {
    color: #767676;
    font-weight: normal;
}

.markdown-body .task-list-item {
    list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
    margin-top: 3px;
}

.markdown-body .task-list-item input {
    margin: 0 0.35em 0.25em -1.6em;
    vertical-align: middle;
}

.markdown-body .plan-choice {
    padding: 15px;
    padding-left: 40px;
    display: block;
    border: 1px solid #e0e0e0;
    position: relative;
    font-weight: normal;
    background-color: #fafafa;
}

.markdown-body .plan-choice.open {
    background-color: #fff;
}

.markdown-body .plan-choice.open .plan-choice-seat-breakdown {
    display: block;
}

.markdown-body .plan-choice-free {
    border-radius: 3px 3px 0 0;
}

.markdown-body .plan-choice-paid {
    border-radius: 0 0 3px 3px;
    border-top: 0;
    margin-bottom: 20px;
}

.markdown-body .plan-choice-radio {
    position: absolute;
    left: 15px;
    top: 18px;
}

.markdown-body .plan-choice-exp {
    color: #999;
    font-size: 12px;
    margin-top: 5px;
}

.markdown-body .plan-choice-seat-breakdown {
    margin-top: 10px;
    display: none;
}

.markdown-body:checked+.radio-label {
    z-index: 1;
    position: relative;
    border-color: #4078c0;
}

.MathJax_Display {
    color: #4B0158;
    padding-top: 5px;
    padding-bottom: 5px;
    /*border: 2px solid #210027;*/
    background-color: #FEFAFF
}</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>chapter6</title></head><body><article class="markdown-body"><h1>
<a id="user-content-chapter-6-gaussian-response-models" class="anchor" href="#chapter-6-gaussian-response-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chapter 6: Gaussian Response Models</h1>

<h2>
<a id="user-content-61-introduction" class="anchor" href="#61-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.1 Introduction</h2>

<p>A response variate $Y$ is one whose distribution has parameters which depends on the value of other variates. For the Gaussian models we have studied so far, we assumed that we had a random sample $Y_1,...,Y_n$ from the same Gaussian distribution $G(\mu,\sigma)$. A Gaussian response model generalizes this to permit the parameters of the Gaussian distribution for $Y_i$ to depend on a vector $x_i$ of covariates (explanatory variates which are measured for the response variate $Y_i$). Gaussian models are by far the most common models used in statistics.</p>

<h4>
<a id="user-content-definition-40" class="anchor" href="#definition-40" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition 40</h4>

<p>A Gaussian response model is one for which the distribution of the response variable $Y$, given the associated vector of <strong>covariates</strong> $x=(x_1,...,x_k)$ for an individual unit, is of the form</p>

<p>$$Y\sim G(\mu(x), \sigma(x))$$</p>

<p>If observations are made on $n$ randomly selected units we write the model as</p>

<p>$$Y_i \sim G(\mu(x_i), \sigma(x_i)) \quad \text{for } i = 1,2,...,n$$</p>

<p>In most examples we will assume $\sigma(x_i)=\sigma$ is constant. This assumption is not necessary but it does make the models easier to analyze. The choice of $\mu(x)$ is guided by past information and on current data from the population or process. The difference between various Gaussian response models is in the choice of the function $\mu(x)$ and the covariates. We often assume $\mu(x_i)$ is a <strong>linear function</strong> of the covariates. These models are called <strong>Gaussian linear models</strong> and can be written as</p>

<p>$$Y_i \sim G(\mu(x_i),\sigma) \text{ for } i = 1,...,n$$</p>

<p>with $\mu(x_i)=\beta_0+\sum_{j=1}^{k}\beta_j x_{ij}$</p>

<p>where $x_i = (x_{i1},...,x_{ik})$ is the vector of known covariates associated with unit $i$ and $\beta_0,...,\beta_k$ are unknown parameters. These models are also referred to as <strong>linear regression models</strong> and $\beta$ are call the regression coefficients.</p>

<h4>
<a id="user-content-remark" class="anchor" href="#remark" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Sometimes the model is written a little differently as</p>

<p>$$Y_i = \mu(x_i) + R_i \text{ where } R_i \sim G(0,\sigma)$$</p>

<p>This splits $Y_i$ into a deterministic component, $\mu(x_i)$ and a random component $R_i$</p>

<p>We now consider estimation and testing procedures for these Gaussian response models. We begin with models which have no covariates so that the observations are all from the same Gaussian distributions.</p>

<h4>
<a id="user-content-gmu-sigma-model" class="anchor" href="#gmu-sigma-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>$G(\mu, \sigma)$ Model</h4>

<p>In chapter 4 and t we discussed estimation and testing hypotheses for samples from a Gaussian distribution. Suppose that $Y\sim G(\mu, \sigma)$ models a response variate $y$ in some population or process. A random sample $Y_1,...,Y_n$ is selected, and we want to estimate the model parameters and possibly to test hypotheses about them. We can write this model in the form</p>

<p>$$Y_i = \mu + R_i \text{ where } R_i \sim G(0,\sigma)$$</p>

<p>so this is a special case of the Gaussian response model in which the mean function is constant. The estimator of the parameter $\mu$ that we used is the maximum likelihood estimator $\bar{Y}=\frac 1n \sum_{i=1}^{n}Y_i$. This estimator is also a "least squares estimator". \bar{Y} has the property that it is closer to the data than any other constant, or</p>

<p>$$\min_\mu \sum_{i=1}^{n} (Y_i-\mu)^2=\sum_{i=1}^{n}(Y_i-\bar{Y})^2$$</p>

<p>You should be able to verify this. It will turn out that the methods for estimation, constructing intervals and tests of hypothesis discussed earlier for the single Gaussian are all special case of the more general methods derived in section 6.5.</p>

<p>In the next section we begin with a simple generalization to the case in which the mean is a linear function of a single covariate.</p>

<h2>
<a id="user-content-62-simple-linear-regression" class="anchor" href="#62-simple-linear-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.2 Simple Linear Regression</h2>

<p>Many studies involve covariates $x$, as described in section 6.1. In this section we consider the case in which there is a single covariate $x$. Consider the model with independent $Y_i$ such that</p>

<p>$$Y_i \sim G(\mu(x_i), \sigma) \text{ where } \mu(x_i)=\alpha+\beta x_i$$</p>

<p>This is of the form with $(\beta_0, \beta_1)$ replaced by $(\alpha, \beta)$.</p>

<p>The likelihood function for $(\alpha, \beta, \sigma)$ is</p>

<p>$$L(\alpha, \beta, \sigma) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi} \sigma} \exp\left[ -1\frac{2\sigma^2} (y_i-\alpha-\beta x_i)^2 \right]$$</p>

<p>or more simply</p>

<p>$$L(\alpha, \beta, \sigma) = \sigma^{-n} \exp \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i-\alpha-\beta x_i)^2 \right]$$</p>

<p>The log likelihood function is</p>

<p>$$l(\alpha, \beta, \sigma) = -n\log \sigma - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i-\alpha-\beta x_i)^2$$</p>

<p>To obtain the maximum likelihood estimates we solve the three equations simultaneously. We obtain the maximum likelihood estimators</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}}$$</p>

<p>$$\tilde\alpha = \bar{Y} - \tilde\beta \bar x$$</p>

<p>$$\tilde\sigma^2 = \frac 1n \sum_{i=1}^n (Y_i-\tilde\alpha-\tilde\beta x_i)^2$$</p>

<p>We will use</p>

<p>$$S_e^2 = \frac{1}{n-2} (S_{yy}-\tilde\beta S_{xy})$$</p>

<p>as the estimator for $\sigma^2$ rather than the maximum likelihood estimator $\sigma^2$ since it can be shown that $E(S_e^2)=\sigma^2$. Note that $S_e^2$ can be more easily calculated using</p>

<p>$$S_e^2 = \frac{1}{n-2} (S_{yy}-\tilde\beta S_{xy})$$</p>

<h4>
<a id="user-content-least-squares-estimation" class="anchor" href="#least-squares-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Least squares estimation</h4>

<p>If we are given the data $(x_i,y_i)$ then one criterion which could be used to obtain a line of "best fit" to these data is to fit the line which minimizes the sum of the squares of the distances between the observed points $(x_i,y_i)$ and the fitted line $y=\alpha + \beta x$. Mathematically this means we want to find the values of $\alpha$ and $\beta$ which minimize the function</p>

<p>$$g(\alpha, \beta) = \sum_{i=1}^n (y_i - (\alpha + \beta x_i))^2$$</p>

<p>Such estimate are called <strong>least squares estimates</strong>. To find the least squares estimates we need to solve the two equations simultaneously. We note that this is equivalent to solving the maximum likelihood equations. In summary we have that the least squares estimates and the maximum likelihood estimates obtained are the same estimates. Of course the method of least squares only provides point estimates of the unknown parameter $\alpha$ and $\beta$ while assuming the model allows us to obtain both estimates and confidence intervals for the unknown parameters. We now show how to obtain confidence intervals based on the model.</p>

<h4>
<a id="user-content-distribution-of-the-estimator-tildebeta" class="anchor" href="#distribution-of-the-estimator-tildebeta" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Distribution of the estimator $\tilde\beta$</h4>

<p>Notice that we can rewrite the expression for $\tilde\beta$ as</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}} = \sum_{i=1}^{n} a_i Y_i \quad \text{where } a_i=\frac{(x_i-\bar{x})}{S_{xx}}$$</p>

<p>to make it clear that $\tilde\beta$ is a linear combination of the Normal random variables $Y_i$ and is therefore Normally distributed with easily obtained expected value and variance. In fact it is easy to show that these non-random coefficients satisfy $\sum_{i=1}^n a_i=0$ and $\sum_{i=1}^{n} a_i x_i=1$ and $\sum_{i=1}^{n} a_i^2 =1/S_{xx}$. Therefore</p>

<p>$$E(\tilde\beta) = \beta$$</p>

<p>Similarly</p>

<p>$$Var(\tilde\beta) = \frac{\sigma^2}{S_{xx}}$$</p>

<p>In summary</p>

<p>$$\tilde\beta \sim G(\beta, \frac{\sigma}{\sqrt{S_{xx}}})$$</p>

<h4>
<a id="user-content-confidence-intervals-for-beta-and-test-of-hypothesis-of-no-relationship" class="anchor" href="#confidence-intervals-for-beta-and-test-of-hypothesis-of-no-relationship" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Confidence intervals for $\beta$ and test of hypothesis of no relationship</h4>

<p>Confidence intervals for $\beta$ are important because the parameter $\beta$ represents the increase in the mean value of $Y$, resulting from an increase of one unit in the value of $x$. As well, if $\beta = 0$ then $x$ has no effect on $Y$ (within the model)</p>

<p>Since</p>

<p>$$\frac{\tilde\beta - \beta}{\sigma/\sqrt{S_{xx}}} \sim G(0,1)$$</p>

<p>holds independently of</p>

<p>$$\frac{(n-2)S_e^2}{\sigma^2} \sim \mathcal{X}^2(n-2)$$</p>

<p>then it follows that</p>

<p>$$\frac{\tilde\beta - \beta}{S_e / \sqrt{S_{xx}}} \sim t(n-2)$$</p>

<p>This pivotal quantity can be used to obtain confidence intervals for $\beta$ and to construct tests of hypotheses about $\beta$.</p>

<p>Using $t$-table find the constant $a$ such that $P(-a\leq T\leq a)=p$ where $T\sim t(n-2)$. </p>

<p>Therefore a $100p\%$ confidence interval for $\beta$ is given by</p>

<p>$$[\hat\beta \pm as_e/\sqrt{S_{xx}}]$$</p>

<p>To test the hypothesis of no relationship or $H_0:\beta = 0$ we use the test statistic</p>

<p>$$\frac{|\tilde\beta - 0|}{S_e/\sqrt{S_{xx}}}$$</p>

<p>with observed value</p>

<p>$$\frac{|\hat\beta - 0|}{s_e/\sqrt{S_{xx}}}$$</p>

<p>then p-value is given by</p>

<p>$$p-value = 2 \left( 1-P\left( T \leq \frac{|\hat{\beta}-0|}{s_e/\sqrt{S_{xx}}} \right) \right)$$</p>

<p>Note also that it can be used to obtain confidence interval or tests for $\sigma$, but these are usually of less interest than inference about $\beta$ or the other quantities below.</p>

<h4>
<a id="user-content-remark-1" class="anchor" href="#remark-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>In regression models we often "redefine" a covariate $x_i$ as $x_i'=x_i-c$ where $c$ is a constant value that makes $\sum_{i=1}^n x_i'$ close to zero. (Often we take $c=\bar{x}$).
The reason for doing this are that it reduces round-off errors in calculations, and that it makes the parameter $\alpha$ more interpretable. Note that $\beta$ does not change if we "center" $x_i$ this way, because</p>

<p>$$E(Y|x)=\alpha+\beta x = \alpha + \beta(x'+c)=(\alpha+\beta c)+ \beta x'$$</p>

<p>Thus, the intercept $\alpha$ changes if we redefine $x$, but not $\beta$. In the examples we consider here we have kept the given definition of $x_i$ for simplicity.</p>

<h4>
<a id="user-content-confidence-interval-for-the-mean-response-muxalpha--beta-x" class="anchor" href="#confidence-interval-for-the-mean-response-muxalpha--beta-x" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Confidence Interval for the mean response $\mu(x)=\alpha + \beta x$</h4>

<p>We are often interested in estimating the quantity $\mu(x) = \alpha + \beta x$ since it represents the mean response at a specified value of the covariate $x$. We can obtain a pivotal quantity for doing this. The maximum likelihood estimator of $\mu(x)$ obtained by replacing the unknown values of $\alpha$, $\beta$ by their maximum likelihood estimators,</p>

<p>$$\tilde\mu(x) = \tilde\alpha + \tilde\beta x = \bar{Y}+\tilde\beta(x-\bar{x})$$</p>

<p>since $\tilde\alpha = \bar{Y} - \tilde\beta \bar{x}$. Since</p>

<p>$$\tilde\beta = \frac{S_{xy}}{S_{xx}}$$</p>

<p>we can rewrite $\tilde\mu(x)$ as</p>

<p>$$\tilde\mu(x) = \bar{Y}+\tilde\beta(x-\bar{x})=\sum_{i=1}^{n} a_i Y_u \text{ where } a_i = \frac 1n + (x-\bar{x}) \frac{(x_i-\bar{x})}{S_{xx}}$$</p>

<p>Since $\tilde\mu(x)$ is a linear combination of Gaussian random variables it has a Gaussian distribution. We can use the above equation to determine the mean and variance of the random variable $\tilde\mu(x)$.</p>

<p>Therefore</p>

<p>$$E(\tilde\mu(x)) = \mu(x)$$</p>

<p>In other words $(\tilde\mu(x))$ is an unbiased estimator of $\mu(x)$. Also</p>

<p>$$Var(\tilde\mu(x)) = \sigma^2 \left( \frac{1}{n} + \frac{(x-\bar{X})^2}{S_{xx}} \right)$$</p>

<p>Note that the variance of $\tilde\mu$ is smallest in the middle of the data, or when $x$ is close to $\bar{x}$ and much larger when $(x-\bar{x})^2$ is large. In summary, we have shown that</p>

<p>$$\tilde\mu(x) \sim G \left( \mu(x), \sigma\sqrt{\frac{1}{n} + \frac{(x-\bar{x})^2}{S_{xx}}} \right)$$</p>

<h4>
<a id="user-content-remark-2" class="anchor" href="#remark-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Note that since $\alpha = \mu(0)$, a $95\%$ confidence interval for $\alpha$, is given with $x= 0$ which gives</p>

<p>$$\tilde\alpha \pm as_e \sqrt{\frac 1n + \frac{\bar{x}^2}{S_{xx}}}$$</p>

<p>In fact one can see that if $\bar{x}$ is large in magnitude (which means the average $x_i$ is large), then the confidence interval for $\alpha$ will be very wide. This would be disturbing if the value $x=0$ is a value of interest.</p>

<h4>
<a id="user-content-prediction-interval-for-future-response" class="anchor" href="#prediction-interval-for-future-response" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prediction Interval for Future Response</h4>

<p>Suppose we want to estimate or predict the $Y$ value for a random unit, not part of the sample, which has a specific value $x$ for its covariate. We can obtain a pivotal quantity that can be used to give a prediction interval (or interval estimate) for the future response $Y$, as follows</p>

<p>Note that $Y\sim G(\mu(x), \sigma)$ or alternatively</p>

<p>$$Y = \mu(x) +R$$</p>

<p>is independent of $Y_1,...,Y_n$. For a point estimator of $Y$ it is natural to use the maximum likelihood estimator $\tilde\mu(x)$ or $\mu(x)$. Moreover the error in the point estimator of $Y$ is given by</p>

<p>$$Y -\tilde\mu(x) = R + (\mu(x) - \tilde\mu(x))$$</p>

<p>Since $R$ is independent of $\tilde\mu(x)$ (it is not connected to the existing sample), it is the sum of independent distributed random variables and is consequently Normally distributed. Since</p>

<p>$$E(Y -  \tilde\mu(x)) = 0$$</p>

<p>and</p>

<p>$$Var(Y - \tilde\mu(x)) = \sigma^2 \left( 1+\frac 1n + \frac{(x-\bar{x})^2}{S_{xx}} \right)$$</p>

<p>we have</p>

<p>$$Y -\tilde\mu(x) \sim G \left( 0,\sigma \left( 1+\frac 1n + \frac{(x-\bar x)^2}{S_{xx}} \right)^{1/2} \right)$$</p>

<h4>
<a id="user-content-remark-3" class="anchor" href="#remark-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Care must be taken in constructing prediction intervals for values of $x$ which lie outside the interval of observed $x_i$'s since this assumes that the linear relationship holds beyond the observed data. It is dangerous since there are no data to support the assumption.</p>

<h4>
<a id="user-content-remark-4" class="anchor" href="#remark-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Note that the confidence interval for $\mu(x)$ and the prediction interval for $Y$ are winder the further away $x$ is from $\bar{x}$. Thus, as we move further away from the "middle" of the $x$'s in the data, we get winder and winder intervals for $\mu(x)$ and $Y$.</p>

<h4>
<a id="user-content-checking-the-model-assumptions-for-simple-linear-regression" class="anchor" href="#checking-the-model-assumptions-for-simple-linear-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Checking the Model Assumptions for Simple Linear Regression</h4>

<p>There are two main components in Gaussian linear response models:</p>

<ol>
<li> The assumption that $Y_i$ (given any covariates $x_i$) is Gaussian with constant standard deviation $\sigma$</li>
<li> The assumption that $E(Y_i)=\mu(x_i)$ is a linear combination of observed covariates with unknown coefficients</li>
</ol>

<p>Models should always be checked. In problems with only one $x$ covariate, a plot of the fitted line superimposed on the scatterplot of the data shows pretty clearly how well the model fits. If there are two or more covariates in the model, residual plots, which are described below, are very useful for checking the model assumptions.</p>

<p>Residuals are defined as the difference between the observed response and the fitted values. Consider the simple linear regression model for which $Y_i \sim G(\mu_i, \sigma)$ where $\mu_i = \alpha + \beta x_i$ and $R_i = Y_i -\mu_i \sim G(0, \sigma)$ The residuals are given by</p>

<p>$$\hat{r}_i = y_i - \hat\mu_i = y_i - \hat\alpha - \hat\beta x_i$$</p>

<p>The idea behind the $\hat{r}_i$ is that they can be thought of as "observed" $R_i$. This isn't exactly correct since we are using $\hat{\mu}$ instead of $\mu$ in $\hat{r}$, but if the model is correct, then the $\hat{r}$ should behave roughly like a random sample from the $G(0,\sigma)$ distribution. The $\hat{r}$ do have some features that can be used to check the model assumptions. Recall that the maximum likelihood estimate of $\alpha$ is $\hat{\alpha} = \bar{y} - \hat{\beta} \bar{x}$ which implies that $\bar{y} - \hat{\alpha} -\hat{\beta} \bar{x} = 0$ or</p>

<p>$$\frac{1}{n} \sum_{i=1}^n \hat{r}_i = 0$$</p>

<p>so that the average of the residuals is always zero.</p>

<p>Residual plots can be used to check the model assumptions. Here are three residual plots which can be used:</p>

<ol>
<li> Plot points $(x_i, \hat{r}_i)$ if the model is satisfactory the points should lie more or less horizontally within a constant band around the line $\hat{r}_i=0$</li>
<li> Plot points $(\hat{\mu}_1, \hat{r}_i)$ if the model is satisfactory the points should lie more or less horizontally within a constant band around the line $\hat{r}_i=0$</li>
<li> Plot a Normal qqplot of the residuals. If the model is satisfactory the points should lie more or less along a straight line.</li>
</ol>
</article></body></html>