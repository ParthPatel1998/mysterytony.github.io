<!DOCTYPE html><html><head><meta charset="utf-8"><style>@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,d09GRgABAAAAAAYcAA0AAAAACjQAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAABGRlRNAAABMAAAABwAAAAca8vGTk9TLzIAAAFMAAAARAAAAFZG1VHVY21hcAAAAZAAAAA+AAABQgAP9AdjdnQgAAAB0AAAAAQAAAAEACICiGdhc3AAAAHUAAAACAAAAAj//wADZ2x5ZgAAAdwAAADRAAABEKyikaNoZWFkAAACsAAAAC0AAAA2AtXoA2hoZWEAAALgAAAAHAAAACQHngNFaG10eAAAAvwAAAAQAAAAEAwAACJsb2NhAAADDAAAAAoAAAAKALIAVG1heHAAAAMYAAAAHwAAACABEAB2bmFtZQAAAzgAAALBAAAFu3I9x/Nwb3N0AAAF/AAAAB0AAAAvaoFvbwAAAAEAAAAAzBdyYwAAAADP2IQvAAAAAM/bz7t4nGNgZGFgnMDAysDB1Ml0hoGBoR9CM75mMGLkYGBgYmBlZsAKAtJcUxgcPsR8iGF2+O/AEMPsznAYKMwIkgMA5REMOXicY2BgYGaAYBkGRgYQsAHyGMF8FgYFIM0ChED+h5j//yEk/3KoSgZGNgYYk4GRCUgwMaACRoZhDwCs7QgGAAAAIgKIAAAAAf//AAJ4nHWMMQrCQBBF/0zWrCCIKUQsTDCL2EXMohYGSSmorScInsRGL2DOYJe0Ntp7BK+gJ1BxF1stZvjz/v8DRghQzEc4kIgKwiAppcA9LtzKLSkdNhKFY3HF4lK69ExKslx7Xa+vPRVS43G98vG1DnkDMIBUgFN0MDXflU8tbaZOUkXUH0+U27RoRpOIyCKjbMCVejwypzJJG4jIwb43rfl6wbwanocrJm9XFYfskuVC5K/TPyczNU7b84CXcbxks1Un6H6tLH9vf2LRnn8Ax7A5WQAAAHicY2BkYGAA4teL1+yI57f5ysDNwgAC529f0kOmWRiYVgEpDgYmEA8AUzEKsQAAAHicY2BkYGB2+O/AEMPCAAJAkpEBFbAAADgKAe0EAAAiAAAAAAQAAAAEAAAAAAAAKgAqACoAiAAAeJxjYGRgYGBhsGFgYgABEMkFhAwM/xn0QAIAD6YBhwB4nI1Ty07cMBS9QwKlQapQW3VXySvEqDCZGbGaHULiIQ1FKgjWMxknMfLEke2A+IJu+wntrt/QbVf9gG75jK577Lg8K1qQPCfnnnt8fX1NRC/pmjrk/zprC+8D7tBy9DHgBXoWfQ44Av8t4Bj4Z8CLtBL9CniJluPXASf0Lm4CXqFX8Q84dOLnMB17N4c7tBo1AS/Qi+hTwBH4rwHHwN8DXqQ30XXAS7QaLwSc0Gn8NuAVWou/gFmnjLrEaEh9GmDdDGgL3B4JsrRPDU2hTOiMSuJUIdKQQayiAth69r6akSSFqIJuA19TrzCIaY8sIoxyrNIrL//pw7A2iMygkX5vDj+G+kuoLdX4GlGK/8Lnlz6/h9MpmoO9rafrz7ILXEHHaAx95s9lsI7AHNMBWEZHULnfAXwG9/ZqdzLI08iuwRloXE8kfhXYAvE23+23DU3t626rbs8/8adv+9DWknsHp3E17oCf+Z48rvEQNZ78paYM38qfk3v/u3l3u3GXN2Dmvmvpf1Srwk3pB/VSsp512bA/GG5i2WJ7wu430yQ5K3nFGiOqgtmSB5pJVSizwaacmUZzZhXLlZTq8qGGFY2YcSkqbth6aW1tRmlaCFs2016m5qn36SbJrqosG4uMV4aP2PHBmB3tjtmgN2izkGQyLWprekbIntJFing32a5rKWCN/SdSoga45EJykyQ7asZvHQ8PTm6cslIpwyeyjbVltNikc2HTR7YKh9LBl9DADC0U/jLcBZDKrMhUBfQBvXRzLtFtjU9eNHKin0x5InTqb8lNpfKv1s1xHzTXRqgKzek/mb7nB8RZTCDhGEX3kK/8Q75AmUM/eLkfA+0Hi908Kx4eNsMgudg5GLdRD7a84npi+YxNr5i5KIbW5izXas7cHXIMAau1OueZhfj+cOcP3P8MNIWLyYOBuxL6DRylJ4cAAAB4nGNgYoAALjDJyIAOWMCiTIxMLDmZedkABtIBygAAAA==) format('woff');
}

* {
    box-sizing: border-box;
}

body {
    width: 980px;
    margin-right: auto;
    margin-left: auto;
}

body .markdown-body {
    padding: 45px;
    border: 1px solid #ddd;
    border-radius: 3px;
    word-wrap: break-word;
}

pre {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body {
  -webkit-text-size-adjust: 100%;
  text-size-adjust: 100%;
  color: #333;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body strong {
  font-weight: bold;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body input {
  font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}

.markdown-body a {
  color: #4078c0;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before {
  display: table;
  content: "";
}

.markdown-body hr:after {
  display: table;
  clear: both;
  content: "";
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
  font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}

.markdown-body .select::-ms-expand {
  opacity: 0;
}

.markdown-body .octicon {
  font: normal normal normal 16px/1 octicons-anchor;
  display: inline-block;
  text-decoration: none;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.markdown-body .octicon-link:before {
  content: '\f05c';
}

.markdown-body:before {
  display: table;
  content: "";
}

.markdown-body:after {
  display: table;
  clear: both;
  content: "";
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body .anchor {
  display: inline-block;
  padding-right: 2px;
  margin-left: -18px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #000;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h1 .anchor {
  line-height: 1;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 .anchor {
  line-height: 1;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h3 .anchor {
  line-height: 1.2;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h4 .anchor {
  line-height: 1.2;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h5 .anchor {
  line-height: 1.1;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body h6 .anchor {
  line-height: 1.1;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  box-sizing: content-box;
  background-color: #fff;
}

.markdown-body code {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .pl-c {
  color: #969896;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: #0086b3;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: #795da3;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
  color: #333;
}

.markdown-body .pl-ent {
  color: #63a35c;
}

.markdown-body .pl-k {
  color: #a71d5d;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
  color: #183691;
}

.markdown-body .pl-v {
  color: #ed6a43;
}

.markdown-body .pl-id {
  color: #b52a1d;
}

.markdown-body .pl-ii {
  background-color: #b52a1d;
  color: #f8f8f8;
}

.markdown-body .pl-sr .pl-cce {
  color: #63a35c;
  font-weight: bold;
}

.markdown-body .pl-ml {
  color: #693a17;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  color: #1d3e81;
  font-weight: bold;
}

.markdown-body .pl-mq {
  color: #008080;
}

.markdown-body .pl-mi {
  color: #333;
  font-style: italic;
}

.markdown-body .pl-mb {
  color: #333;
  font-weight: bold;
}

.markdown-body .pl-md {
  background-color: #ffecec;
  color: #bd2c00;
}

.markdown-body .pl-mi1 {
  background-color: #eaffea;
  color: #55a532;
}

.markdown-body .pl-mdr {
  color: #795da3;
  font-weight: bold;
}

.markdown-body .pl-mo {
  color: #1d3e81;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb;
}

.markdown-body .plan-price-unit {
  color: #767676;
  font-weight: normal;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 0.35em 0.25em -1.6em;
  vertical-align: middle;
}

.markdown-body .plan-choice {
  padding: 15px;
  padding-left: 40px;
  display: block;
  border: 1px solid #e0e0e0;
  position: relative;
  font-weight: normal;
  background-color: #fafafa;
}

.markdown-body .plan-choice.open {
  background-color: #fff;
}

.markdown-body .plan-choice.open .plan-choice-seat-breakdown {
  display: block;
}

.markdown-body .plan-choice-free {
  border-radius: 3px 3px 0 0;
}

.markdown-body .plan-choice-paid {
  border-radius: 0 0 3px 3px;
  border-top: 0;
  margin-bottom: 20px;
}

.markdown-body .plan-choice-radio {
  position: absolute;
  left: 15px;
  top: 18px;
}

.markdown-body .plan-choice-exp {
  color: #999;
  font-size: 12px;
  margin-top: 5px;
}

.markdown-body .plan-choice-seat-breakdown {
  margin-top: 10px;
  display: none;
}

.markdown-body :checked+.radio-label {
  z-index: 1;
  position: relative;
  border-color: #4078c0;
}
</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>chapter6</title></head><body><article class="markdown-body"><p><a href="http://tonyli.tk/">&lt;- Go Back</a></p>

<h1>
<a id="user-content-chapter-6-eigenvectors-and-diagonalizationnewcommandvvecnewcommandbmathbbnewcommandvsetkvv_1cdotsvv_knewcommandvsetnvv_1cdotsvv_nnewcommandvxvecxnewcommandbvmathbbvnewcommandxtimesnewcommandbmbeginbmatrixnewcommandbmendendbmatrixnewcommandvmbeginvmatrixnewcommandvmendendvmatrix" class="anchor" href="#chapter-6-eigenvectors-and-diagonalizationnewcommandvvecnewcommandbmathbbnewcommandvsetkvv_1cdotsvv_knewcommandvsetnvv_1cdotsvv_nnewcommandvxvecxnewcommandbvmathbbvnewcommandxtimesnewcommandbmbeginbmatrixnewcommandbmendendbmatrixnewcommandvmbeginvmatrixnewcommandvmendendvmatrix" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chapter 6: Eigenvectors and Diagonalization$\newcommand{\v}{\vec}$$\newcommand{\b}{\mathbb}$$\newcommand{\vsetk}{\v{v_1},\cdots,\v{v_k}}$$\newcommand{\vsetn}{\v{v_1},\cdots,\v{v_n}}$$\newcommand{\vx}{\vec{x}}$$\newcommand{\bv}{\mathbb{V}}\newcommand{\x}{\times}$$\newcommand{\bm}{\begin{bmatrix}}$$\newcommand{\bmend}{\end{bmatrix}}$$\newcommand{\vm}{\begin{vmatrix}}$$\newcommand{\vmend}{\end{vmatrix}}$</h1>

<h2>
<a id="user-content-61-matrix-of-a-linear-mapping-similar-matrices" class="anchor" href="#61-matrix-of-a-linear-mapping-similar-matrices" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.1 Matrix of a Linear Mapping, Similar Matrices</h2>

<h4>
<a id="user-content-matrix-of-a-linear-operator" class="anchor" href="#matrix-of-a-linear-operator" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Matrix of a Linear Operator</h4>

<blockquote>
<p>The standard matrix $[L]$ of a linear operator $L:\b{R}^n \rightarrow \b{R}^n$ satisfies $L(\vx)=[L]\vx$. Thus, to define the matrix $[L]_B$ of $L$ with respect to any basis $B$ of $\b{R}^n$, we mimic this formula in $B$-coordinates instead of standard coordinates. That is, we want
$$[L(\vx)]_B=[L]_B [\vx]_B$$
Let $B={\v{v}_1,...,\v{v}_n}$. Then, we can write $\vx = b_1\v{v}_1+\cdots +b_n\v{v}_n$ and we get
$$\begin{align*} [L(\vx)]_B &amp;= [L( b_1\v{v}_1+\cdots +b_n\v{v}_n)]_B \\
&amp;= [b_1L(\v{v}_1)+\cdots +b_nL(\v{v}_n)]_B \\
&amp;= b_1[L(\v{v}_1)]_B +\cdots +b_n[L(\v{v}_n)]_B \\
&amp;= \bm [L(\v{v}_1)]_B &amp; \cdots &amp; [L(\v{v}_n)]_B \bmend \bm b_1 \\ \vdots \\ b_n \bmend \end{align*}$$
Therefore, we have $[L(\vx)]_B$ as a product of a matrix and $[\vx]_B$ as desired.</p>
</blockquote>

<h4>
<a id="user-content-definition-b-matrix" class="anchor" href="#definition-b-matrix" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: B-matrix</h4>

<p>Let $B=\{\vsetn\}$ be a basis for $\b{R}^n$ and let $L:\b{R}^n\rightarrow \b{R}^n$ be a linear operator. The <strong>$B$-matrix</strong> of $L$ is defined to be
$$[L]_B = \bm [L(\v{v}_1)]_B &amp; \cdots &amp; [L(\v{v}_n)]_B \bmend$$
It satisfies $[L(\vx)]_B=[L]_B [\vx]_B$.</p>

<h4>
<a id="user-content-definition-diagonal-matrix" class="anchor" href="#definition-diagonal-matrix" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Diagonal Matrix</h4>

<p>An $n\x n$ matrix $D$ is said to be a <strong>diagonal matrix</strong> if $d_{ij}=0$ for all $i\neq j$. We denote a diagonal matrix by
$$diag \{d_{11},d_{22},...,d_{nn} \}$$</p>

<h4>
<a id="user-content-similar-matrices" class="anchor" href="#similar-matrices" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Similar Matrices</h4>

<p>Let $L:\b{R}^n \rightarrow \b{R}^n$ be a linear operator with standard matrix $A=[L]$ and let $B=\{\vsetn\}$ be a basis for $\b{R}^n$. Then by definition, we have
$$[L]_B=\bm [A\v{v}_1]_B &amp; \cdots &amp; [A\v{v}_n]_B \bmend$$</p>

<p>We know that the change of coordinates matrix from $B$-coordinates to $S$-coordinates is $P=[\v{v}_1 \cdots \v{v}_n]$. Hence, we have $[\vx]_B = P^{-1}\vx$ for any $vx\in \b{R}^n$. Since $A\v{v}_i\in\b{R}^n$ for $1\leq i \leq n$, we can get
$$\begin{align*} 
[L]_B &amp;= \bm [A\v{v}_1]_B &amp; \cdots &amp; [A\v{v}_n]_B \bmend \\
&amp;= \bm P^{-1}A\v{v}_1 &amp; \cdots &amp; P^{-1}A\v{v}_n \bmend \\
&amp;= P^{-1}A \bm \v{v}_1 &amp; \cdots &amp; \v{v}_n \bmend \\
&amp;= P^{-1}AP \end{align*}$$</p>

<h4>
<a id="user-content-remark" class="anchor" href="#remark" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>You can also show that $[L]_B = P^{-1}[L]P$, by showing that $[L]_B[\vx]_B=P{-1}[L]P[\vx]_B$ for all $\vx\in\b{R}$ by simplifying the right hand side of the equation.</p>

<h4>
<a id="user-content-theorem-1" class="anchor" href="#theorem-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 1</h4>

<p>If $A$ and $B$ are $n\x n$ matrices such that $P^{-1}AP=B$ for some invertible matrix $P$, then
1.  rankA = rankB
2.  detA = detB
3.  trA = trB where tr A is defined by $\sum_{i=1}^{n}a_{ii}$ and is called the trace of a matrix</p>

<h4>
<a id="user-content-definition-similar" class="anchor" href="#definition-similar" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Similar</h4>

<p>If $A$ and $B$ be $n\x n$ matrices such that $P^{-1}AP=B$ for some invertible matrix $P$, then $A$ is said to be <strong>similar</strong> to $B$.</p>

<h4>
<a id="user-content-remark-1" class="anchor" href="#remark-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>Observe that if $P^{-1}AP=B$, then taking $Q=p^{-1}$ we get the $Q$ is an invertible matrix such that $A=PBP^{-1}=Q^{-1}BQ$. So, the similarity property is symmetric. In particular, we usually will just say that $A$ and $B$ are similar.</p>

<h2>
<a id="user-content-62-eigenvalues-and-eigenvectors" class="anchor" href="#62-eigenvalues-and-eigenvectors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.2 Eigenvalues and Eigenvectors</h2>

<p>Let $A=[L]$ be the standard matrix of a linear operator $L:\b{R}^n\rightarrow \b{R}^n$. To determine how to construct an invertible matrix $P$ such that $P^{-1}AP=D$ is diagonal, we work in reverse. That is, we will assume that such a matrix $P$ exists and use this to find that properties $P$ and $D$ must have.</p>

<p>Let$P=[\v{v}_1 \cdots \v{v}_n]$ and let $D= diag(\lambda_1,...,\lambda_n)=[\lambda_1\v{e}_1 \cdots \lambda_n \v{e}_n]$ such that $P^{-1}AP=D$, or alternately $AP=PD$. This gives
$$\begin{align*} A[\v{v}_1 \cdots \v{v}_n] &amp;= P[\lambda_1\v{e}_1 \cdots \lambda_n \v{e}_n] \\
[A\v{v}_1 \cdots A\v{v}_n] &amp;= [\lambda_1 P \v{e}_1 \cdots \lambda_n P \v{e}_n] \\
[A\v{v}_1 \cdots A\v{v}_n] &amp;= [\lambda_1 v{v}_1 \cdots \lambda_n v{v}_n] \end{align*}$$</p>

<p>Thus, we must have $A\v{v}_i=\lambda_i \v{v}_i$ for $1\leq i \leq n$. Moreover, for $P$ to be invertible, the columns of $P$ must be linearly independent. In particular, $\v{v}_1\neq\v{0}$ for $1\leq i \leq n$.</p>

<h4>
<a id="user-content-definition-eigenvalue-eigenvector--eigenpair" class="anchor" href="#definition-eigenvalue-eigenvector--eigenpair" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Eigenvalue, Eigenvector &amp; Eigenpair</h4>

<p>Let $A$ be an $n\x n$ matrix. If there exists a vector $\v{v}\neq \v{0}$ such that $A\v{v}=\lambda\v{v}$, then $\lambda$ is called an <strong>eigenvalue</strong> of $A$ and $\v{v}$ is called an <strong>eigenvector</strong> of $A$ corresponding to $\lambda$. The pair $(\lambda, \v{v})$ is called an <strong>eigenpair</strong>.</p>

<h4>
<a id="user-content-definition" class="anchor" href="#definition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition</h4>

<p>Let $L:\b{R}^n\rightarrow\b{R}^n$ be a linear operator. If there exists a vector $\v{v}\neq\v{0}$ such that $L(\v{v})=\lambda \v{v}$, then $\lambda$ is call an <strong>eigenvalue</strong> of $L$ and $\v{v}$ is call an <strong>eigenvector</strong> of $L$ corresponding to $\lambda$.</p>

<h4>
<a id="user-content-definition-characteristic-polynomial" class="anchor" href="#definition-characteristic-polynomial" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Characteristic Polynomial</h4>

<p>Let $A$ be an $n\x n$ matrix. the <strong>characteristic polynomial</strong> of $A$ is the $n$-th degree polynomial
$$C(\lambda)=det(A-\lambda I)$$</p>

<h4>
<a id="user-content-theorem-1-1" class="anchor" href="#theorem-1-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 1</h4>

<p>A scalar $\lambda$ is an eigenvalue of an $n\x n$ matrix $A$ if and only if $C(\lambda)=0$.</p>

<p>We also see that the set of all eigenvectors associated with an eigenvalue $\lambda$ is the nullspace of $A-\lambda I$ not including the zero vector.</p>

<h4>
<a id="user-content-definition-eigenspace" class="anchor" href="#definition-eigenspace" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Eigenspace</h4>

<p>Let $A$ be an $n\x n$ matrix with eigenvalue $\lambda$. We call the nullspace of $A-\lambda I$ the <strong>eigenspace</strong> of $\lambda$. The eigenspace is denoted $E_\lambda$.</p>

<h4>
<a id="user-content-remarks" class="anchor" href="#remarks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remarks</h4>

<ol>
<li> It is important to remember that the set of all eigenvectors for the eigenvalue $\lambda$ of $A$ is all vectors in $E_\lambda$ excluding the zero vector.</li>
<li> Since the eigenspace is just the nullspace of $A-\lambda I$, it is also a subspace of $\b{R}^n$.</li>
</ol>

<h4>
<a id="user-content-theorem-2" class="anchor" href="#theorem-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 2</h4>

<p>If $A$ is an $n\x n$ upper or lower triangular matrix, then the eigenvalues of $A$ are the diagonal entries of $A$.</p>

<h4>
<a id="user-content-definition-algebraic-multiplicity--geometric-multiplicity" class="anchor" href="#definition-algebraic-multiplicity--geometric-multiplicity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Algebraic Multiplicity &amp; Geometric Multiplicity</h4>

<p>Let $A$ be an $n\x n$ matrix with eigenvalue $\lambda_1$. the <strong>algebraic multiplicity</strong> of $\lambda_1$, denoted $a_{\lambda_1}$, is the number of times that $\lambda_1$ is a root of the characteristic polynomial $C(\lambda)$. That is if $C(\lambda)=(\lambda-\lambda_1)^kC_1(\lambda)$, where $C_1(\lambda_1)\neq 0$, then $a_{\lambda_1}=k$. The <strong>geometric multiplicity</strong> of $\lambda$, denoted $g_{\lambda_1}$, is the dimension of its eigenspace. So, $g_{\lambda_1}=dim(E_{\lambda_1})$.</p>

<h4>
<a id="user-content-lemma-3" class="anchor" href="#lemma-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lemma 3</h4>

<p>Let $A$ and $B$ be similar matrices, then $A$ and $B$ have the same characteristic polynomial and hence the same eigenvalues.</p>

<h4>
<a id="user-content-theorem-4" class="anchor" href="#theorem-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 4</h4>

<p>If $A$ is an $n\x n$ matrix with eigenvalue $\lambda_1$, then $1\leq g_{\lambda_1} \leq a_{\lambda_1}$.</p>

<h2>
<a id="user-content-63-diagonalization" class="anchor" href="#63-diagonalization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.3 Diagonalization</h2>

<h4>
<a id="user-content-definition-diagonalizable" class="anchor" href="#definition-diagonalizable" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Definition: Diagonalizable</h4>

<p>An $n\x n$ matrix $A$ is said to be <strong>diagonalizable</strong> if $A$ is similar to a diagonal matrix $D$. If $P^{-1}AP=D$, then we way that $P$ <strong>diagonalizes</strong> $A$.</p>

<h4>
<a id="user-content-theorem-1-diagonalization-theorem" class="anchor" href="#theorem-1-diagonalization-theorem" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 1: Diagonalization Theorem</h4>

<p>An $n\x n$ matrix $A$ is diagonalizable if and only if there exists a basis $\{\vsetn\}$ for $\b{R}^n$ of eigenvectors of $A$.</p>

<h4>
<a id="user-content-lemma-2" class="anchor" href="#lemma-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lemma 2</h4>

<p>If $A$ is an $n\x n$ matrix with eigenpairs $(\lambda_1,\v{v}_1),...,(\lambda_k,\v{v}_k)$ where $\lambda_i \neq \lambda_j$ for $i\neq j$, then $\{\vsetk\}$ is linearly independent.</p>

<h4>
<a id="user-content-theorem-3" class="anchor" href="#theorem-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 3</h4>

<p>If $A$ is an $n\x n$ matrix with district eigenvalues $\lambda_1,...,\lambda_k$ and $B_i=\{\v{v_{i,1}},...,\v{v_{i,g_{\lambda_i}}}\}$ is a basis for the eigenspace of $\lambda_i$ for $1\leq i \leq k$, then $B_1\cup ... \cup B_k$ is a linearly independent set.</p>

<h4>
<a id="user-content-corollary-4" class="anchor" href="#corollary-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Corollary 4</h4>

<p>If $A$ is an $n\x n$ matrix with distinct eigenvalues $\lambda_1,...,\lambda_k$, then $A$ is diagonalizable if and only if $g_{\lambda_i}=a_{\lambda_i}$ for $1\leq i\leq k$.</p>

<h4>
<a id="user-content-corollary-5" class="anchor" href="#corollary-5" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Corollary 5</h4>

<p>If $A$ is an $n\x n$ matrix with $n$ distinct eigenvalues, then $A$ is diagonalizable.</p>

<h4>
<a id="user-content-algorithm" class="anchor" href="#algorithm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Algorithm</h4>

<p>To diagonalize an $n\x n$ matrix $A$, or show that $A$ is not diagonalizable:</p>

<ol>
<li> Find and factor the characteristic polynomial $C(\lambda)=det(A-\lambda I)$.</li>
<li> Let $\lambda_1,...,\lambda_n$ denote the $n$-root of $C(\lambda)$ (repeated according to multiplicity). If any of the eigenvalues $\lambda_i$ are not real, then $A$ is not diagonalizable over $\b{R}$.</li>
<li> Find a basis for the eigenspace of each $\lambda_i$ by finding a basis for the nullspace of $A-\lambda_i I$.</li>
<li> If $g_{\lambda_i}&lt;a_{\lambda_i}$ for any $\lambda_i$, then $A$ is not diagonalizable. Otherwise, form a basis $\{\v{v}_1,...,\v{v}_n\}$ for $\b{R}^n$ of eigenvectors of $A$ by using Theorem 3. Let $P=[\v{v}_1 \cdots \v{v}_n]$. Then, $P^{-1}AP=diag(\lambda_1,...,\lambda_n)$ where $\lambda_i$ is an eigenvalue corresponding to the eigenvector $\v{v}_i$ for $1\leq i\leq n$.</li>
</ol>

<h4>
<a id="user-content-remark-2" class="anchor" href="#remark-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Remark</h4>

<p>It is important to remember that the answer is not unique. We can arrange the linearly independent eigenvectors of $A$ as the columns of $P$ in any order. We only have to ensure the entry $d_{ii}$ in $D$ is an eigenvalue of $A$ of the eigenvector in the $i$-th column of $P$.</p>

<h4>
<a id="user-content-theorem-6" class="anchor" href="#theorem-6" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 6</h4>

<p>If $\lambda_1,...,\lambda_n$ are all the eigenvalues of an $n\x n$ matrix $A$, then
$$trA=\lambda_1 + \cdots + \lambda_n$$</p>

<h2>
<a id="user-content-64-powers-of-matrices" class="anchor" href="#64-powers-of-matrices" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6.4 Powers of Matrices</h2>

<h4>
<a id="user-content-theorem-1-2" class="anchor" href="#theorem-1-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Theorem 1</h4>

<p>Let $A$ be an $n\x n$ matrix. If there exists a matrix $P$ and diagonal matrix $D$ such that $P^{-1}AP=D$, then
$$A^{k}=PD^kP^{-1}$$</p>
</article></body></html>